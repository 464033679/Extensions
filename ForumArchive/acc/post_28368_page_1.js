[{"Owner":"nikokoneko","Date":"2017-02-11T12:46:02Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tHi_co_\n_lt_/p_gt_\n\n_lt_p_gt_\n\tI noticed that Babylon_t_s implementation of VR camera rig is such that it calculates distortion correction inside of fragment shader. Since the calculations are done per pixel_co_ it results in a steep performance drop_co_ especially on high-density screens_co_ which renders the rig unusable for any mobile phone. On a simplest of scenes_co_ I get only 30fps on Google Pixel.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tI wonder why this particular method has been chosen over_co_ say_co_ displaying the rendered texture on a dense plane (20x20) and then performing all calculations by vertex of that plane. With this method we would be performing calculations some 400 times per eye (on a 20x20 mesh)_co_ versus over 900 000 times (for each pixel on a QHD screen_co_ for example).\n_lt_/p_gt_\n\n_lt_p_gt_\n\tWhat I am referring to is the 2nd approach described here_dd_\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_a href_eq__qt_http_dd_//smus.com/vr-lens-distortion/_qt_ rel_eq__qt_external nofollow_qt__gt_http_dd_//smus.com/vr-lens-distortion/_lt_/a_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\tBoth WebVR polyfill and Google VR View use this method and I notice no performance drop AT ALL when running their examples.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tThe reason I ask is because I am thinking of developing this method for Babylon_co_ simply because current pixel-based implementation is unfortunately completely unusable. But before I start I_t_d_co_ like to know if there is some underlying problem_co_ inherent to Babylon_co_ to implement this method?\n_lt_/p_gt_\n\n_lt_p_gt_\n\tThanks\n_lt_/p_gt_\n\n_lt_p_gt_\n\t \n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"Deltakosh","Date":"2017-02-13T21:35:02Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tHello_co_ we started developing the distortion correction at pixel level because it was easier to test and implement.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tBut now you are completely right it comes at an expensive cost. I would really appreciate your help if you can provide per vertex implementation (Which could be turned on/off)\n_lt_/p_gt_\n\n_lt_p_gt_\n\tWe can even think about using it as default and allow users to opt in to use the per pixel version\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"nikokoneko","Date":"2017-02-14T15:04:41Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tI_t_d like to help. Right now I_t_m running on several deadlines_co_ but when I finish I will take a stab at it._lt_br /_gt_\n\tBefore I start diving into thousands of lines of the current Babylon js code_co_ where would you recommend me to look at?_lt_br /_gt_\n\tI should have no problem writing the actual shader *_co_ but I don_t_t know anything on how PostProcess is currently implemented in Babylon_co_ I guess I should start there?\n_lt_/p_gt_\n\n_lt_p_gt_\n\t(EDIT_dd_ actually Google has posted the actual shaders as a part of their WebVR polyfill)\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"JCPalmer","Date":"2017-02-14T16:36:57Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t_lt_p_gt_\n\tDefinitely look at Camera.ts.  That is where sub-cameras are defined_co_ and where the rigs are set up.  Implementing regardless of whether movement is determined by accelerometer or a gamepad is a much better design.\n_lt_/p_gt_\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"}]