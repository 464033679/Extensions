[{"Owner":"JCPalmer","Date":"2018-09-24T15:44:43Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tI am using a kinect2 for data capture inside of Blender.  For all but the root bone_co_ I am using the _lt_a href_eq__qt_https_dd_//www.youtube.com/watch?v_eq_qqJY8PVRCzc_qt_ rel_eq__qt_external nofollow_qt__gt_absolute joint position method_lt_/a_gt_.  Trying to use the rotation quaternions is a nightmare_co_ which is not helped by_dd_\n_lt_/p_gt_\n\n_lt_ul_gt_\n\t_lt_li_gt_\n\t\tBlender being right-handed &amp_sm_ Kinect2 being left\n\t_lt_/li_gt_\n\t_lt_li_gt_\n\t\tY &amp_sm_ Z dimensions switched\n\t_lt_/li_gt_\n\t_lt_li_gt_\n\t\tData capturing &amp_sm_ not mirroring\n\t_lt_/li_gt_\n\t_lt_li_gt_\n\t\tquaternion method is all or nothing.  Complete garbage where you cannot figure out what is wrong.  With location data you can sort of see what you are doing wrong.\n\t_lt_/li_gt_\n_lt_/ul_gt_\n\n_lt_p_gt_\n\tI get decent results_co_ when facing forward_co_ but if I do a twirl location data can never work.  I was think of using the quaternion data solely for the rootbone.  Unfortunately_co_ the data looks kind of weird.  Below_co_ is a clockwise twirl.  I have not corrected for being a mirror yet.  The second group is using Blender_t_s _lt_a href_eq__qt_https_dd_//docs.blender.org/api/blender_python_api_current/mathutils.html?highlight_eq_to_euler#mathutils.Quaternion.to_euler_qt_ rel_eq__qt_external nofollow_qt__gt_quaternion.to_euler(_t_XYZ_t_)_lt_/a_gt_.  Can anyone explain this data?  Do people even try to data capture stuff like this?\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_a class_eq__qt_ipsAttachLink ipsAttachLink_image_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/uploads/monthly_2018_09/1016081293_rotationdata.JPG.0d10a5199f7e2f60ecd7f5ec6222822f.JPG_qt_ data-fileid_eq__qt_20179_qt_ rel_eq__qt__qt__gt__lt_img class_eq__qt_ipsImage ipsImage_thumbnailed_qt_ data-fileid_eq__qt_20179_qt_ src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/monthly_2018_09/1894702535_rotationdata.thumb.JPG.29915456f9bec3d5089088a4d6662f4b.JPG_qt_ alt_eq__qt_1894702535_rotationdata.thumb.JPG.29915456f9bec3d5089088a4d6662f4b.JPG_qt_ /_gt__lt_/a_gt_\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"JCPalmer","Date":"2018-09-24T17:26:39Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tDoing some more searching_co_ I found some info on _lt_a href_eq__qt_https_dd_//social.msdn.microsoft.com/Forums/en-US/8f405acb-7758-4f5c-a297-24bdce27d042/understanding-subject-orientation?forum_eq_kinectv2sdk_qt_ rel_eq__qt_external nofollow_qt__gt_using the location data_lt_/a_gt_ for getting orientation to camera as well.  I had tried to do this myself as well_co_ but using the hips instead of shoulders.  Mine was a real kludge.  The last response was_dd_\n_lt_/p_gt_\n\n_lt_blockquote class_eq__qt_ipsQuote_qt_ data-ipsquote_eq__qt__qt__gt_\n\t_lt_div class_eq__qt_ipsQuote_citation_qt__gt_\n\t\tQuote\n\t_lt_/div_gt_\n\n\t_lt_div class_eq__qt_ipsQuote_contents_qt__gt_\n\t\t_lt_p_gt_\n\t\t\tThat_t_s actually pretty easy_dd_\n\t\t_lt_/p_gt_\n\n\t\t_lt_p_gt_\n\t\t\tXvector _eq_  (Right Shoulder Position) - (Left Shoulder Position)\n\t\t_lt_/p_gt_\n\n\t\t_lt_p_gt_\n\t\t\tYvector _eq_ (Head Position) - (SpineBase Position)\n\t\t_lt_/p_gt_\n\n\t\t_lt_p_gt_\n\t\t\tZvector _eq_ CrossProduct(Xvector_co_Yvector)\n\t\t_lt_/p_gt_\n\n\t\t_lt_p_gt_\n\t\t\t \n\t\t_lt_/p_gt_\n\n\t\t_lt_p_gt_\n\t\t\tZvector will give you the overall pointing direction of the body relative to the camera\n\t\t_lt_/p_gt_\n\n\t\t_lt_hr /_gt_\n\t\t_lt_p_gt_\n\t\t\tVicente Penades\n\t\t_lt_/p_gt_\n\t_lt_/div_gt_\n_lt_/blockquote_gt_\n\n_lt_p_gt_\n\tNot sure exactly how to do this yet_co_ but I know for a fact that the location data is consistent all the time.  Any comments?\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"dbawel","Date":"2018-09-25T00:05:41Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tI had serious issues capturing into Blender. I ran my Kinect(s) into MotionBuilder and then exported FBX to Blender without any problems. In working with motion capture for 20+ years_co_ I see too many problems with capturing into Blender right now_sm_ until someone writes a proper plugin which is simple to use.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tDB\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"}]