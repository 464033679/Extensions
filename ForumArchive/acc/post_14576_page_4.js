[{"Owner":"JCPalmer","Date":"2015-06-04T20:00:32Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_Are saying the anaglyph is worse?  I found some red blue glasses in a book on Mars.  Though except for color_co_ it looked good.  If you are sayin stereo stuff is worse.  I do not side by side compare. Looked slightly _qt_better_qt__co_ but I have no actual metrics to quantify_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"Vousk-prod.","Date":"2015-06-04T21:18:45Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_In fact you can_t_t really detect those misalignements with glasses or with a stereo dedicated display_co_ because our brain is pretty smart and it tends to compensate the defects. Those problems have to be checked by hand (well... by eyes _lt_img src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/default_tongue.png_qt_ alt_eq__qt__dd_P_qt_ srcset_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/tongue@2x.png 2x_qt_ width_eq__qt_20_qt_ height_eq__qt_20_qt__gt_). Not so difficult to see if you know what to look after. And the rule is simple_co_ every similar points in both images must be on the same horizontal line_co_ if you see a vertical shift_co_ the stereo is not good. And the wider the shift the harder for the brain to fuse_co_ resulting on pain and strain for the viewer. Since real eyes are always on the EXACT same line_co_ images produces by the eyes are perfectly aligned on every point. That_t_s what the brain loves._lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"Vousk-prod.","Date":"2015-06-04T21:21:43Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_Add more 3D objets everywhere in your test scene_co_ and put textures on it_co_ it would be easier to see. Also it would be usefull to be able to freely rotate the camera with the mouse._lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"JCPalmer","Date":"2015-06-05T14:15:53Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_Glad you published an empirical test.  What might be good is if you could snap a window shot_co_ then annotate it with the worst example you can find._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_I really cannot run fast enough right now_co_ to think I can beat a 2.1 release.  Change any names you feel are important &amp_sm_ PR ASAP.  This is a new feature_co_ which ideally should have been done in alpha_co_ not at the tail end of beta_co_ especially with all the re-factoring (though I am glad it was done).  We can always improve the results / performance_co_ but any term changes after release will cause breaks in user code.  It actually works on a 3D TV_co_ so we have a valid base line._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_I take your point about having more elements in the test scene_co_ as opposed to moving a single object to and away.  After I can see the test illustrated in a picture_co_ I will think along the lines of making the cursor shaped as a long horizontal line_co_ or a cursor which moves a line.  That way you can easily do the test you describe._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_I mentioned my entire repository back up to you before_co_ I store the entire repository as a single OS file.  Will copy this file / repository off_co_ for later reference._lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"Vousk-prod.","Date":"2015-06-05T14:29:42Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_No need to design a cursor as a long horizontal line_co_ to check alignement I simply open on other window (explorer for instance) and drag it above the 3D scene_co_ using the upper border of the floating window as a perfectly horizontal ruler _lt_img src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/default_wink.png_qt_ alt_eq__qt__sm_)_qt_ srcset_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/wink@2x.png 2x_qt_ width_eq__qt_20_qt_ height_eq__qt_20_qt__gt__lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"dbawel","Date":"2015-06-06T00:55:24Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_Hi Jeff_co__lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_If you can show fov and any other data relevant to the sub cameras_co_ this would help to evaluate the resulting images._lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"Vousk-prod.","Date":"2015-06-08T03:00:05Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_So_co_ I_t_ve just PRed the stereoscopic system refactoring._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_What has changed_co_ mainly_dd__lt_br_gt_- Renamed everything related to stereo according to the regular names_lt_br_gt_- Renamed some function for better clarity_lt_br_gt_- Throwed away SUB_CAMERAID_A and SUB_CAMERAID_B constants. I found them irrelevant _co_ particularly if we let rigs open for any kind of setups we don_t_t know in advance. We have the sub cameras array and that should be enough for devs to use and extend class for more complex rigs_co_ it_t_s up to the user to define its cameras and IDs._lt_br_gt_- Put a generic rig parameters instead of every single VR and stereo params inside the global camera class (to provide better flexibility for later)_lt_br_gt_- Inverted cameras (depth was calculated inside out)_lt_br_gt_- Put babylon.anaglyphCamera.js in babylon.stereoscopicCamera.js (renamed babylon.stereoscopicCameras.js) because an anaglyh camera is a stereoscopic camera_co_ it_t_s just the final output which is different_co_ there is no reason to treat them differently (quite the contrary_co_ it would be disturbing for users to separate them)_lt_br_gt_- Added STEREOSCOPY_CONVERGENCE_MODE and STEREOSCOPY_PARALLEL_MODE constants for _cameraRigParams.stereoMode flag to let you implement your parallel mode alongside convergence mode_co_ JCPalmer (if we decide to implement both to let user choose which one better suits its need)._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_BUT there_t_s still many work to be done_co_ because_lt_br_gt_1. the stereoscopy procuded is not ok_co_ sorry to tell you that JCP _lt_img src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/default_sad.png_qt_ alt_eq__qt__dd_(_qt_ srcset_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/sad@2x.png 2x_qt_ width_eq__qt_20_qt_ height_eq__qt_20_qt__gt_ (when we rotate camera the alignement is shifting verticaly up and down and the parallax is kind of rotating with the camera _lt_img src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/default_wacko.png_qt_ alt_eq__qt__dd_wacko_dd__qt__gt_ _co_ that_t_s a bit strange because for ArcRotateCamera the alpha value is simply shifting both side and that seems a logical approach _lt_img src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/default_huh.png_qt_ alt_eq__qt__dd_huh_dd__qt__gt_ ). The VR left and right cams computations are based on an other method I don_t_t totaly understand _lt_img src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/default_happy.png_qt_ alt_eq__qt_^_^_qt_ srcset_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/happy@2x.png 2x_qt_ width_eq__qt_20_qt_ height_eq__qt_20_qt__gt_ but it seems ok. Maybe we should use the same kind._lt_br_gt_2. the regular stereoscopy usage need to define interocular value in metric unit and not an angle unit (I_t_m talking about that halfSpace value_co_ now renamed to a stereoHalfAngle_co_  provisonnaly converted from interaxialDistance value)._lt_br_gt_3. We need to provide stereoscopy for FreeCamera as well._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_Oh and I think that _getVRProjectionMatrix shouldn_t_t be directly in Camera class_co_ it_t_s a bit specific_co_ no_co_ what do you think ?_lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_Typically_co_ in production a virtual stereo rig is used that way_dd__lt_br_gt_-&gt_sm_ we have a camera we can manipulate as usual_co_ that camera has a target we can move and an interrocular distance we can change real time. While moving camera and objects in the scene_co_ those three params (camera position_co_ target position - defining where focus point will be on screen -_co_ interaxial distance - defining depth amount -) are constantly modified._lt_/p_gt__lt_p_gt_Behind the scene_co_ this camera is in fact a helper acting exactly like a camera (that could be a camera not rendered)_co_ and the two rendered cameras (left and right) are simply parented to that central camera/helper_co_ horizontally shifted on both side by the half of interoccular distance_co_ and they all share the same target. This way we are not calcultating the position of the two cameras each frame but we simply benefits from the parenting system. The convergence is automaticaly set thanks to the shared target_co_ and_co_ on interrocular changes the two cameras are re-shifted. When coming to stereoscopic production the target and the interaxial distance are strictly required because they must be changed to create proper nice and _qt_audience safe_qt_ depth all the time. For a game engine_co_ that_t_s maybe not as important as for a video_co_ but we need to provide specialists what they are familiar with _lt_img src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/default_cool.png_qt_ alt_eq__qt_B)_qt__gt__lt_br_gt_Currently_co_ the implementation is rather different. That_t_s not a problem by itself_co_ we have to implements the less resources consuming version_co_ as long as people can use it as usual stereoscopic cameras._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_Erm… that_t_s strange I cannot login anymore to bjs docs…  (maybe it_t_s because of the new doc project ?)_lt_br_gt_I wanted to fix the _qt_contribute page_qt_ (eg. Approved Naming Convention page) because now when changing or adding files it_t_s not the gulpfile we have to edit anymore_co_ it_t_s the config.json file._lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"dbawel","Date":"2015-06-08T04:07:34Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_Jeff_co__lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_I wanted to let you know that I tested the xperia against samsung_co_ ipad_co_ ios_co_ and pc_co_ and other than fps_co_ all of my gui elements using bGui worked exactly the same - resolution dependant of course.  I didn_t_t have the chance to test with the dialogue extension_co_ but I can_t_t imagine it_t_s a Sony issue.  The waterproofing is simply a seal on ports_co_ but quite effective as I dropped my tablet in the dish sink by mistake and it was perfectly fine._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_Did I understand that you benchmarked at only 5fps on a post process?  If this is correct_co_ try turning on your developer options and adjust hardware scaling to 0.5.  Just use caution with other settings.  I hope you were saying you only lost 5fps.  Also_co_ I_t_m not sure why you wouldn_t_t be able to render interlaced odd/even frames and maintain 60fps - scene dependant of course.  I_t_m also exploring web workers as I have plenty of cpu left and you should be able to thread a post render process with remaining overhead.  Just a few thoughts.  Great work on the new cameras! _lt_img src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/default_smile.png_qt_ alt_eq__qt__dd_)_qt_ srcset_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/smile@2x.png 2x_qt_ width_eq__qt_20_qt_ height_eq__qt_20_qt__gt__lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"Vousk-prod.","Date":"2015-06-08T09:16:19Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_Actually the postprocess for stereoscopy is just here to split view in two. Wouldn_t_t be more optimised to simply define the two camera viewports as half screen size and not use postprocess at all ? (except for anaglyph of course)_lt_/p_gt__lt_p_gt_The only interest I see to use postprocess for stereoscopy is if we decide to compensate the keystoning problem (would be important to do that_co_ to provide a perfect stereo brain safe proof)._lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"JCPalmer","Date":"2015-06-08T16:22:35Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_@db - First there are controls in the recent tester to let you change both the FOV and spacing.  Yes_co_ that was 5 fps_co_ not a 5 fps drop.  Web workers run on a core separate from render loop.  All modern mobile devices are multi-core_co_ so the fact you get better throughput_co_ does not mean anything for this application.  Dropping hardware scaling is only good once admitting defeat.  Dialog wise_co_ my dialogs disappear now.  Was getting 60 fps with hidden dialogs &amp_sm_ no post process.  Only thing added was post process._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_@Vousk - I originally had 2 viewports.  The viewports for side by side_co_ same as VR_co_ did not shrink though.  They only removed part of the image from the left &amp_sm_ right_co_ but the zombie (used for early tests) stayed the same size / shape._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_Working right now on a canvas+ alternative_co_ Intel XDK.  But before even that_co_ I want to take a deep look at engine_t_s fps metering.  I do not need some kind of n sec average to be calc_t_ed and displayed.  Will settle for a frame counter.  I will know when I switched it on_co_ to calc duration.  Calc fps by dividing by the frame count.  Write to console.  Using this will allow for consistency_co_ but not interfere._lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"JCPalmer","Date":"2015-06-08T17:30:34Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_Hey_co__lt_/p_gt__lt_p_gt_I just mde the changes to the tester to accommodate names changes.  See a problem / difference with how the interaxialDistance is handled in _lt_strong_gt_setCameraRigMode_lt_/strong_gt_ from _lt_strong_gt_setCameraRigParameter_lt_/strong_gt_.  One does a div by 0.0637_lt_strong_gt_.  _lt_/strong_gt_Can see this in the tester updated.  Click on one of the 3D rigs_co_ you see_lt_/p_gt__lt_p_gt_first way.  Change distance_co_ &amp_sm_ you see the other._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_If CDN not cut yet_co_ could this still be made consistant for 2.1?_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"dbawel","Date":"2015-06-08T17:51:20Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_@JCP - all good points_co_ my friend.  I like your statement that attenuating hardware scaling is only good once admitting defeat - this is so very true.  I_t_m curious to see how close the calculations for metering fps mathematically mirror the rendering result on your tablet.  This should be good info and possibly provide further insight into BJS cpu management and cache. I look forward to your next test(s)_co_ and thanks for playing this out to the end.  We all benefit from your hard work  Lots of eyes watching this one. _lt_img src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/default_rolleyes.gif_qt_ alt_eq__qt__dd_rolleyes_dd__qt__gt_.  I even saw Oculus on the thread recently - as they must wonder what the hell we_t_re doing with our cameras over here - however_co_ if they don_t_t release the Rift soon_co_ others will begin to relegate them to a secondary support position as well.  Their loss. _lt_img src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/default_ph34r.png_qt_ alt_eq__qt__dd_ph34r_dd__qt_ srcset_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/ph34r@2x.png 2x_qt_ width_eq__qt_20_qt_ height_eq__qt_20_qt__gt__lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_DB_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"Deltakosh","Date":"2015-06-08T18:36:32Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_For the specific case of rigCameras I will accept PR and update the 2.1 afterwards_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"JCPalmer","Date":"2015-06-12T14:44:40Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_Ok_co_ am solely working on performance right now_co_ using the convergence method of the final 2.1 BJS.  No changes have been made to the test scene other than performance metering_co_ so I am not going to republish it._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_I went with a logging approach_co_ adding the smallest possible extra overhead to the render loop.  I found nothing of value that could be reused from Engine_t_s fps metering.  Engine also has very low overhead by merely computing the duration of a frame in the render loop.  If you wish to do fps metering_co_ however_co_ it starts managing an array of the last 60 samples.  Then it computes the fps from the samples every frame.  If using debug layer_co_ this value is displayed externally._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_I just want an average of say a 10 or 20 second interval with no overhead.  The clicking of buttons on the test scene after running 10 secs or so_co_ would trigger a calc-log-reset sequence.  To prep for also checking on XDK_co_ I have implemented this in a file close to the app.js that is generated when you start a project.  Here it is_dd__lt_br_gt_ _lt_/p_gt__lt_pre class_eq__qt_ipsCode prettyprint_qt__gt_var frameCount_sm_var startTime_sm_function onAppReady() {    if( navigator.splashscreen &amp_sm_&amp_sm_ navigator.splashscreen.hide ) {   // Cordova API detected        navigator.splashscreen.hide() _sm_    }        var canvas _eq_ document.getElementById(_qt_renderCanvas_qt_)_sm_    canvas.screencanvas _eq_ true_sm_ // for CocoonJS    var engine _eq_ new BABYLON.Engine(canvas_co_ true)_sm_    var scene _eq_ new BABYLON.Scene(engine)_sm_            shape_key.initScene(scene)_sm_    createDialog(scene_co_ scene.activeCamera)_sm_           prepCloth(scene.getMeshByID(_qt_Cloth_qt_)_co_ scene)_sm_    frameCount _eq_ 0_sm_    startTime _eq_ BABYLON.Tools.Now_sm_    \t    scene.activeCamera.attachControl(canvas)_sm_        engine.runRenderLoop(function () {            scene.render()_sm_            frameCount++_sm_    })_sm_}// this is an XDK event_sm_ when not using XDK_co_ place in &lt_sm_body onload_eq__qt_onAppReady()_qt_&gt_sm_document.addEventListener(_qt_app.Ready_qt__co_ onAppReady_co_ false) _sm_// in order for logging to work in XDK_co_ change _qt_dev.LOG_qt_ in _qt_init-dev.js_qt_ to _qt_true_qt_function logPerformance(description) {    var totalWallClock _eq_ BABYLON.Tools.Now - startTime_sm_    var fps _eq_ (frameCount / (totalWallClock / 1000)).toFixed(2)_sm_    BABYLON.Tools.Log(description + _qt_ was performed @ _qt_ + fps + _qt_ fps_qt_)_sm_    // reset for the next activity    frameCount _eq_ 0_sm_    startTime _eq_ BABYLON.Tools.Now_sm_}_lt_/pre_gt__lt_p_gt_Running this on the Sony / Android tablet_co_ my I got very comparable #_t_s to the on screen values of canvas+.  Doing no 3D rendering produced 30 fps with the dialog visible &amp_sm_ 60 when hidden.  When viewing any of the 3D modes_co_ this dropped to 5-6 fps regardless of the dialog being visible or not._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_Here is where I have new stuff to report.  I decided to also to run the same tests on CocoonJS_t_s canvas+ on the iPad.  The iPad does not support miracast_co_ so it can not actually be used to display on a 3D tv_co_ but it is a controlled way to try to find the cause.  (FYI_co_ the Android numbers are without broadcasting to tv_co_ though they did not down when doing so)._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_For no 3D rig the iPad numbers were 29 / 59 fps.  Almost the same.  For any of the 3D modes_co_ the #_t_s also matched Android in that it did not matter whether the dialog was visible or not.  That is where the similarity ends though.  The performance drop was not nearly as bad.  They all were in the 19-21 range._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_One could extrapolate that on iPad_co_ the parallel method might produce very acceptable performance._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_Not ready to call what it might be the reason for the difference.  Am going to follow through with the XDK version_co_ so see if they might additional clues._lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"dbawel","Date":"2015-06-13T13:22:52Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_Thanks for the technical specs.  This helps everyone understand what is CPU heavy.  Also_co_ I_t_m happy to see others use XDK_co_ as this is a great tool for my development benchmarks. _lt_img src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/default_smile.png_qt_ alt_eq__qt__dd_)_qt_ srcset_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/smile@2x.png 2x_qt_ width_eq__qt_20_qt_ height_eq__qt_20_qt__gt__lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"JCPalmer","Date":"2015-07-06T16:09:57Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_Note to self.  Trying to get baking to work ALL the time_co_ with multiple meshes_co_ went to Blender 2.75.  One of the new features they also added stereoscopic cameras.  Here is the link when I get back to this_co_ incase there is something useful. _lt_a href_eq__qt_http_dd_//www.blender.org/manual/render/workflows/multiview.html_qt_ rel_eq__qt_external nofollow_qt__gt_http_dd_//www.blender.org/manual/render/workflows/multiview.html_lt_/a_gt__lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"}]