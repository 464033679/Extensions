[{"Owner":"dinos","Date":"2018-10-29T16:00:35Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tI am looking for a way to _qt_import/convert_qt_ _lt_strong_gt_sophisticated vertex animations from Cinema 4D into Babylon_lt_/strong_gt_. I have done so numerous times into Unity3D_sm_ for which the _lt_a href_eq__qt_https_dd_//www.youtube.com/watch?v_eq_r80iOjhjh1s_qt_ rel_eq__qt_external nofollow_qt__gt_process is to [link to example Video]_lt_/a_gt__lt_span_gt__dd__lt_/span_gt_\n_lt_/p_gt_\n\n_lt_ul_gt_\n\t_lt_li_gt_\n\t\tbake the mograph etc animations into keyframes inside cinema 4d\n\t_lt_/li_gt_\n\t_lt_li_gt_\n\t\texport as an FBX file which includes the point cache as an extra _qt_.pla_qt_ file\n\t_lt_/li_gt_\n\t_lt_li_gt_\n\t\timport it into unity (traditionally with a thrid party plugin called _qt__lt_a href_eq__qt_https_dd_//assetstore.unity.com/packages/tools/modeling/mega-fiers-644_qt_ rel_eq__qt_external nofollow_qt__gt_mage fiers_lt_/a_gt__qt_ and its _qt_mega point cache_qt_ feature). However_co_ unity3D will add native support for point cache animations in the upcoming release.\n\t_lt_/li_gt_\n_lt_/ul_gt_\n\n_lt_p_gt_\n\t_lt_img class_eq__qt_ipsImage ipsImage_thumbnailed_qt_ data-fileid_eq__qt_20698_qt_ src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/monthly_2018_10/image.png.f590ec62b973922814487aa25d7e8d68.png_qt_ alt_eq__qt_image.png.f590ec62b973922814487aa25d7e8d68.png_qt_ /_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_strong_gt_Question_lt_/strong_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\tHow do you guys get Cinema 4D mograph animations into babylon? Is there maybe also another way?\n_lt_/p_gt_\n\n_lt_p_gt_\n\tCould Babylon maybe add PLA-Support? That would unlock plenty of creative input.\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_strong_gt_Old &amp_sm_ Related Threads_lt_/strong_gt_\n_lt_/p_gt_\n\n_lt_ul_gt_\n\t_lt_li_gt_\n\t\t2015 _lt_a href_eq__qt_http_dd_//www.html5gamedevs.com/topic/13469-cinema-4d-pla-animation-export/_qt_ rel_eq__qt__qt__gt_Cinema 4D PLA animation export_lt_/a_gt_\n\t_lt_/li_gt_\n\t_lt_li_gt_\n\t\t2017 _lt_a href_eq__qt_https_dd_//www.reddit.com/r/Cinema4D/comments/6al9c8/baking_effectors_for_unity/_qt_ rel_eq__qt_external nofollow_qt__gt_Baking Effectors for Unity_lt_/a_gt_\n\t_lt_/li_gt_\n_lt_/ul_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"Deltakosh","Date":"2018-10-29T17:18:08Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tWell first welcome _lt_span_gt__lt_img alt_eq__qt__dd_)_qt_ data-emoticon_eq__qt_true_qt_ height_eq__qt_20_qt_ src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/default_smile.png_qt_ srcset_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/smile@2x.png 2x_qt_ title_eq__qt__dd_)_qt_ width_eq__qt_20_qt__gt__lt_/span_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_span_gt_We do support morph targets which can be perhaps used here directly ? (from 3dsmax or Maya)_lt_/span_gt_\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"Deltakosh","Date":"2018-10-29T17:20:11Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tAlso would love to get others feedback on this feature\n_lt_/p_gt_\n\n_lt_p_gt_\n\tCan you share a fbx scene so we can understand what can be done here?\n_lt_/p_gt_\n\n_lt_p_gt_\n\tPinging _lt_a contenteditable_eq__qt_false_qt_ data-ipshover_eq__qt__qt_ data-ipshover-target_eq__qt_http_dd_//www.html5gamedevs.com/profile/32589-patrickryan/?do_eq_hovercard_qt_ data-mentionid_eq__qt_32589_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/profile/32589-patrickryan/_qt_ rel_eq__qt__qt__gt_@PatrickRyan_lt_/a_gt_\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"dinos","Date":"2018-10-30T21:36:46Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tThank you! I have spend some time to build a _qt_simple_qt_ example for a typical Cinema4D -&gt_sm_ fbx/pla -&gt_sm_ engine workflow. You see the example as follows_co_ where the letter B (for Babylon) is inflated via a soft body dynamic in C4D over 90 frames. You find the FBX with its .pla folder and the important .mc file hosted online (link at the end of the post).\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_img alt_eq__qt_babylon-pla-render.gif.e6e42a5a842daefd10bca839e25a6f40.gif_qt_ class_eq__qt_ipsImage ipsImage_thumbnailed_qt_ data-fileid_eq__qt_20718_qt_ src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/monthly_2018_10/babylon-pla-render.gif.e6e42a5a842daefd10bca839e25a6f40.gif_qt_ /_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_strong_gt_Setup_lt_/strong_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\tThis is a simple soft body animation without any third party plugins. I use Cinema 4D Release 20_sm_ anybody should be able to open the original file _lt_a class_eq__qt_ipsAttachLink_qt_ data-fileid_eq__qt_20721_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/applications/core/interface/file/attachment.php?id_eq_20721_qt_ rel_eq__qt__qt__gt_original.c4d_lt_/a_gt_ .\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_a class_eq__qt_ipsAttachLink ipsAttachLink_image_qt_ data-fileid_eq__qt_20724_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/uploads/monthly_2018_10/00-softbody_in_c4d.PNG.b92a31281f601487512e5b56af3e0b4a.PNG_qt_ rel_eq__qt__qt__gt__lt_img alt_eq__qt_00-softbody_in_c4d.thumb.PNG.be5d88ee7e072708133032a3419793f9.PNG_qt_ class_eq__qt_ipsImage ipsImage_thumbnailed_qt_ data-fileid_eq__qt_20724_qt_ src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/monthly_2018_10/00-softbody_in_c4d.thumb.PNG.be5d88ee7e072708133032a3419793f9.PNG_qt_ /_gt__lt_/a_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_strong_gt_Exporting an FBX with PLA (for anybody coming from Google_co_ finding this post)_lt_/strong_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\tThe conversion follows this video here (_lt_a href_eq__qt_https_dd_//youtu.be/r80iOjhjh1s?t_eq_584_qt_ rel_eq__qt_external nofollow_qt__gt_https_dd_//youtu.be/r80iOjhjh1s?t_eq_584_lt_/a_gt_). Baisically_co_ the _qt_letter_b_qt_ subdevision object is first converted into an Alembic (right click -&gt_sm_ Convert to Alembic + Delete). Than dragged into the Animation Timeline and Converted into Keyframes via Functions -&gt_sm_ Bake Objects. Finally_co_ the Alembic is made editable (deleting the reference to the external alembic file).\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_a class_eq__qt_ipsAttachLink ipsAttachLink_image_qt_ data-fileid_eq__qt_20722_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/uploads/monthly_2018_10/01-pla_keyframes_in_c4d.PNG.4ec124cdb244f2e2afc7cd26f2bd903b.PNG_qt_ rel_eq__qt__qt__gt__lt_img alt_eq__qt_01-pla_keyframes_in_c4d.thumb.PNG.5ca5a9c523e9886c4729f271d30633bb.PNG_qt_ class_eq__qt_ipsImage ipsImage_thumbnailed_qt_ data-fileid_eq__qt_20722_qt_ src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/monthly_2018_10/01-pla_keyframes_in_c4d.thumb.PNG.5ca5a9c523e9886c4729f271d30633bb.PNG_qt_ /_gt__lt_/a_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\tFinally_co_ the FBX is exported by going to File -&gt_sm_ Export -&gt_sm_ FBX with the following settings (selection only_dd_ select the object first).\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_img alt_eq__qt_02-fbx_export_settings_in_c4d.PNG.55e5ec537d0c4680bfd8d486f461a817.PNG_qt_ class_eq__qt_ipsImage ipsImage_thumbnailed_qt_ data-fileid_eq__qt_20723_qt_ src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/monthly_2018_10/02-fbx_export_settings_in_c4d.PNG.55e5ec537d0c4680bfd8d486f461a817.PNG_qt_ /_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_strong_gt_Ready for Import via FBX &amp_sm_ .pla folder_lt_/strong_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\tOnce the process is complete_co_ the fbx files_co_ including a folder called *.pla_co_ is exported. The important file for any vertex animation here is the included (and rather large) *.mc file.\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_img alt_eq__qt_03-fbx_with_pla_folder.PNG.c1df25e3816361b21f1fa60a587e9455.PNG_qt_ class_eq__qt_ipsImage ipsImage_thumbnailed_qt_ data-fileid_eq__qt_20725_qt_ src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/monthly_2018_10/03-fbx_with_pla_folder.PNG.c1df25e3816361b21f1fa60a587e9455.PNG_qt_ /_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\tThe *.mc file is the point cache_co_ that in case of unity_co_ you would import via _qt_mega fierce -&gt_sm_ point cache_qt_ into the engine_dd_ _lt_a href_eq__qt_http_dd_//www.west-racing.com/mf/?page_id_eq_1335_qt_ rel_eq__qt_external nofollow_qt__gt_http_dd_//www.west-racing.com/mf/?page_id_eq_1335_lt_/a_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_img alt_eq__qt_04-mega-fiers-tool-example.PNG.2b4e4622ff1af5ab548092baf3982381.PNG_qt_ class_eq__qt_ipsImage ipsImage_thumbnailed_qt_ data-fileid_eq__qt_20726_qt_ src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/monthly_2018_10/04-mega-fiers-tool-example.PNG.2b4e4622ff1af5ab548092baf3982381.PNG_qt_ /_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\tIts written in C# with source access. Maybe a nice way to understand how to parse the relevant files.\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_strong_gt_FBX Example File &amp_sm_ Download_lt_/strong_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\tThe baked files are way to big to upload here. So you find them under the following link for download_dd_ \n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_a href_eq__qt_https_dd_//drive.google.com/open?id_eq_1k02wiAWcQzZ1lSavFYlnWp6RjaaIF3CA_qt_ rel_eq__qt_external nofollow_qt__gt_https_dd_//drive.google.com/open?id_eq_1k02wiAWcQzZ1lSavFYlnWp6RjaaIF3CA_lt_/a_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\tAgain_co_ the important files are\n_lt_/p_gt_\n\n_lt_ul_gt_\n\t_lt_li_gt_\n\t\toriginal.c4d --- (animation before baking_sm_ aka procedural)\n\t_lt_/li_gt_\n\t_lt_li_gt_\n\t\tbaked.c4d --- (animation is baked to keyframes)\n\t_lt_/li_gt_\n\t_lt_li_gt_\n\t\tfbx-export/\n\t\t_lt_ul_gt_\n\t\t\t_lt_li_gt_\n\t\t\t\tletter_b_demo.fbx --- (the model)\n\t\t\t_lt_/li_gt_\n\t\t\t_lt_li_gt_\n\t\t\t\tletter_b_demo.pla/ --- (folder)\n\t\t\t\t_lt_ul_gt_\n\t\t\t\t\t_lt_li_gt_\n\t\t\t\t\t\t_lt_strong_gt_letter_b_pla.mc_lt_/strong_gt_ --- (the point cache)\n\t\t\t\t\t_lt_/li_gt_\n\t\t\t\t\t_lt_li_gt_\n\t\t\t\t\t\tletter_b_pla.xml --- (some meta information... not really relevant)\n\t\t\t\t\t_lt_/li_gt_\n\t\t\t\t_lt_/ul_gt_\n\t\t\t_lt_/li_gt_\n\t\t_lt_/ul_gt_\n\t_lt_/li_gt_\n_lt_/ul_gt_\n\n_lt_p_gt_\n\tI hope this helps_co__lt_br /_gt_\n\tbest\n_lt_/p_gt_\n\n_lt_p_gt_\n\tDino\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"Deltakosh","Date":"2018-10-31T16:08:27Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tOk I_t_ll wait for Patrick to tell us if this could be imported in Maya or Max and used as Morph target\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"dinos","Date":"2018-11-10T11:18:34Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tAny news regarding this?\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"Deltakosh","Date":"2018-11-11T03:18:29Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tPinging _lt_a contenteditable_eq__qt_false_qt_ data-ipshover_eq__qt__qt_ data-ipshover-target_eq__qt_http_dd_//www.html5gamedevs.com/profile/32589-patrickryan/?do_eq_hovercard_qt_ data-mentionid_eq__qt_32589_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/profile/32589-patrickryan/_qt_ rel_eq__qt__qt__gt_@PatrickRyan_lt_/a_gt_\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"PatrickRyan","Date":"2018-11-12T19:08:14Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tHi_co_ _lt_a contenteditable_eq__qt_false_qt_ data-ipshover_eq__qt__qt_ data-ipshover-target_eq__qt_http_dd_//www.html5gamedevs.com/profile/33226-dinos/?do_eq_hovercard_qt_ data-mentionid_eq__qt_33226_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/profile/33226-dinos/_qt_ rel_eq__qt__qt__gt_@dinos_lt_/a_gt_! Sorry for the delay in response. I dug into the files you supplied and unfortunately what you are doing right now isn_t_t supported in Babylon.js. Let me break this all down for you and offer some alternatives_co_ though it will greatly change your approach to building your assets. \n_lt_/p_gt_\n\n_lt_ul_gt_\n\t_lt_li_gt_\n\t\tThe mesh is a 54_co_334 vertex mesh_co_ 108_co_672 triangles\n\t_lt_/li_gt_\n\t_lt_li_gt_\n\t\t Per vertex animation data is used as well as node transform animation on top of that generated from mo-graph simulation\n\t_lt_/li_gt_\n\t_lt_li_gt_\n\t\t 90 frame animation\n\t_lt_/li_gt_\n\t_lt_li_gt_\n\t\t No material\n\t_lt_/li_gt_\n_lt_/ul_gt_\n\n_lt_p_gt_\n\tThe main problem with bringing this directly into Babylon is that we do not support pure vertex animation without the use of a skeleton or morph target. The main issue here is that per vertex data is very heavy and thus expensive to store when you are calculating 60 frames a second. With bone animation and morph target animation_co_ we are able to calculate easily within the shader_co_ but with vertex data_co_ we have to load new data each frame which has a huge overhead.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tYou also have the issue of larger file sizes for download on the web because you are storing 90 frames of transform data for each of the 54K vertices in a file that needs to be downloaded. With bones_co_ you store the transform information on each joint (which will usually be fewer than 50) and a skin for the mesh_co_ which is the influence on a vertex from up to four bones in normalized weights_co_ to determine its final location on a frame. This is far less data to download on the web. With morph targets_co_ you store multiple mesh states and then a target for interpolation per vertex per frame. This carries with it a larger file size than bone animation due to the extra triangle lists copying your original mesh but this is cheaper than per vertex animation because the shader can calculate the interpolation between the start position of a vertex and the morph target_t_s position while keeping everything stored in memory. \n_lt_/p_gt_\n\n_lt_p_gt_\n\tThink of it this way_co_ with a skeleton_co_ we load one mesh and one joint hierarchy. With morph target_co_ we load a mesh and up to four morph target meshes. With per vertex animation we will load 90 meshes. We haven_t_t had this type of request before because we are rendering 60 frames per second on the web with a single core while also needing to target lower-end machines. Most of the content that will be created for web will use game industry optimization and tricks as there is a limit to rendering resources and we need to decide where the trade offs must be made. \n_lt_/p_gt_\n\n_lt_p_gt_\n\tNow some options that will change your workflow but make this possible would be this_dd_\n_lt_/p_gt_\n\n_lt_ul_gt_\n\t_lt_li_gt_\n\t\t Determine if you can do an effect that you like with a skeleton. You could potentially create a skeleton rig in the B that would mimic your balloon animation_co_ but it would be much more work to rig and animate as you won_t_t be able to rely on the ease of the simulations in C4D. \n\t_lt_/li_gt_\n\t_lt_li_gt_\n\t\t Determine if you can develop motion to be able to utilize morph targets. You could rely on C4D simulations to generate your target meshes at the extremes of the animation_co_ and then use your morphs to get motion that feels similar. The drawback with this approach is that you can only have 4 morph targets and interpolate between each of them per frame. In this way_co_ you can get some interesting mixes_co_ but you lose control over the subtleties of your shapes because of the limitation of morphs you can have. This is where planning the motion around knowing you are using morph targets comes in. It_t_s easier to use a portion of your current workflow in generating your morphs_co_ but are more limited in the motion you can create. \n\t_lt_/li_gt_\n\t_lt_li_gt_\n\t\t Ask yourself if you NEED 3D objects for everything in your scene. If you have some motion that you don_t_t allow the user to move around_co_ you could render out an animated sequence or video that gets rendered on a quad. You are able to move the quad around_co_ but don_t_t have the overhead of vertex animation of any type. You can use your current workflow for this type of element and set up a sprite sheet animation or video.\n\t_lt_/li_gt_\n_lt_/ul_gt_\n\n_lt_p_gt_\n\tSome things to keep in mind when building assets for WebGL\n_lt_/p_gt_\n\n_lt_ul_gt_\n\t_lt_li_gt_\n\t\tTry to keep your vertex count low and utilize normal textures for more detail. Use the minimum amount of vertices to render your silhouette only. Let all other high frequency detail live in your texture set. \n\t_lt_/li_gt_\n\t_lt_li_gt_\n\t\t Look at the overall stats for your scene. Even if you keep your vertex counts low (5 - 10K) using large textures or many of them will also hit performance.\n\t_lt_/li_gt_\n\t_lt_li_gt_\n\t\t Optimize your UV shells so that you can pack more geometry into each texture. If you have an area that isn_t_t important_co_ reduce its texel density to allow for more UV shells on the sheet.\n\t_lt_/li_gt_\n\t_lt_li_gt_\n\t\t Keep your skeletons as simple as you can. Objects that don_t_t move don_t_t need bones.\n\t_lt_/li_gt_\n_lt_/ul_gt_\n\n_lt_p_gt_\n\tIf you have more questions or would like examples_co_ please let me know. We haven_t_t had a lot of people coming from motion graphics to Babylon.js yet_co_ so we haven_t_t had a lot of requests like this one. Take care and I hope this helps somewhat_co_ even if it_t_s not the answer you were hoping for.\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"dinos","Date":"2018-11-13T09:58:47Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tThank you _lt_a contenteditable_eq__qt_false_qt_ data-ipshover_eq__qt__qt_ data-ipshover-target_eq__qt_http_dd_//www.html5gamedevs.com/profile/32589-patrickryan/?do_eq_hovercard_qt_ data-mentionid_eq__qt_32589_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/profile/32589-patrickryan/_qt_ rel_eq__qt__qt__gt_@PatrickRyan_lt_/a_gt_ for your extensive reply. I am actually a 3D Enthusiast but a Software Engineer for Web/Mobile/+. In that sense_co_ I feel you of scooping out the drawbacks of WebGL. In fact at first I wanted to provide a low poly sphere to cube pla animation. But I knew that the immediate answer to that would have been morph targets.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tWith the contrived inflation example_co_ that — due to creases and wrinkles — would be “impossible” to cramp into 4 (or 8?) morph targets. I wanted to see whats possible from a workflow perspective neglecting performance for now.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tSo_co_ going into follow up questions\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_strong_gt_Pre-Compile Solution_lt_/strong_gt__lt_br /_gt_\n\tI think its clear that a pla folder with an actual vertex cache data file of various formats_co_ such as MCX (Maya)_co_ PC2 (Max) or ABC (Alembic) is impractical to serve on the fly/on the web. Do you think its possible to come up with a “smart” transpile solution? I.e. going from the FBX vertex cache to a js file/format that facilitates per-vertex animation/morph/interpolation?\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_b_gt_Automatic Workflow Alternatives_lt_/b_gt__lt_br /_gt_\n\tAs you said_co_ creating something like the example above manually could be an extensive endeavour. So I wonder if there is an indirect but semi-automatic alterntive? Maya? I.e. are you aware of a way to “convert” a pla timeline into optimal morph targets (pick the best states by staying truest to the original animation). I know I could make snapshots manually — but picking the right moments on the timeline seems like a lot of try and error.\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_b_gt_Looking for Approaches_lt_/b_gt__lt_br /_gt_\n\tI am wondering if I should investigate the possibility of building a pla -&gt_sm_ morph targets transpiler or a way to compress vertex animations (interpolation per vertex over time) as a JS/WASM solution. The problem is that I don‘t have a clue about shader magic necessary for GPU based interpolations. What do you think? _lt_span class_eq__qt_ipsEmoji_qt__gt_🤷🏻‍♂️_lt_/span_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_span class_eq__qt_ipsEmoji_qt__gt_🐣_lt_/span_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\tI think the reason that no motion designers are showing up is rather a chicken egg problem_co_ than a lack of interest. Also see the thread refs in my first post and the likes on github for Cinema 4D support (an industry standard VFX tool).\n_lt_/p_gt_\n\n_lt_p_gt_\n\tBest_lt_br /_gt_\n\tDino\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"PatrickRyan","Date":"2018-11-14T07:55:00Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tHappy to explore more of this topic with you_co_ _lt_a contenteditable_eq__qt_false_qt_ data-ipshover_eq__qt__qt_ data-ipshover-target_eq__qt_http_dd_//www.html5gamedevs.com/profile/33226-dinos/?do_eq_hovercard_qt_ data-mentionid_eq__qt_33226_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/profile/33226-dinos/_qt_ rel_eq__qt__qt__gt_@dinos_lt_/a_gt_. Here are my thoughts on possible approaches with the understanding that neither glTF nor Babylon currently support vertex animation so any direction that we explore that is outside of bone/morph target animation will need support and ratification in those formats.\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_strong_gt_Pre-Compile Solution_lt_/strong_gt__lt_br /_gt_\n\tThere was a lot of work done for the Actiongram experience for HoloLens that involved streaming mesh data as well as video textures mapped to them. This is basically what you were looking at before and from what I understand I believe they developed a system to store and stream the delta to the vertex position in such a way as to be able to run at 60 fps on HoloLens which needs to target mobile specs due to power consumption needs coupled with the real-time tracking and reconstruction system. You can see the product of that work in this _lt_a href_eq__qt_https_dd_//www.youtube.com/watch?v_eq_Scm6czeuqlM_qt_ rel_eq__qt_external nofollow_qt__gt_video_lt_/a_gt_. The trick with that which wouldn_t_t need to be ported here is to sync the video texture with the streaming mesh. Our team has reached out to the team that created that tech and are trying to start a conversation about it to see if there is anything that we can leverage for future features. In the mean time_co_ due to the complexity of not only finding a way to stream the data in an efficient way_co_ we would need to get support in the formats and with glTF would mean ratification of a new feature. That would be a longer term goal but something worth investigating if we can speak with the Acitongram team on their tech.\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_strong_gt_Automatic Workflow Alternative_lt_/strong_gt__lt_br /_gt_\n\tFinding a way to pick the optimal targets of a simulation to convert to morphs would be the most straight forward approach_co_ but also would need some experimentation. My initial thought would be to analyze the bounding box of the simulation and look for the axis with the greatest delta in length. Choosing the frames that gave you the extremes of the delta would likely give you two good candidates for your first two morphs. Then I would choose the axis with the second greatest delta and take frames from its two extremes for the other morphs. This would likely get you part of the way there_co_ but then you would still need to remap curves to fit the target transitions. Scrubbing the simulation to see where in the timeline each extreme sits would give you a general idea of how to author a curve to match the extremes with the morph animations. You would likely need to manually choose what the rest pose is with the mesh (your default mesh) as that would be hard to procedurally determine. The system would also likely need a looping option which would need to invert the curves and animate back to the rest pose for animations that need to loop.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tIf I were to choose a path to bringing a mograph simulation into real time rendering_co_ it would likely look like the automatic solution above. With the chicken and egg problem you posed_co_ at least the morph target method is already supported so it is just creating an art pipeline to get the asset into Babylon.js that is missing. I have done a bunch of work with morph target animation and planning to create sample assets for glTF and I keep coming back to the same conclusion_co_ you have to really plan what  you want to do with the animation and target small achievable results because of the limitation of 4 states beyond the rest pose. But with some tinkering_co_ there may be a proof of concept out there to guide very strategic mograph assets into WebGL. I just don_t_t know if this would solve the problem without more investigation.\n_lt_/p_gt_\n\n_lt_p_gt_\n\t \n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"dinos","Date":"2018-11-15T09:22:56Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\t_lt_a contenteditable_eq__qt_false_qt_ data-ipshover_eq__qt__qt_ data-ipshover-target_eq__qt_http_dd_//www.html5gamedevs.com/profile/32589-patrickryan/?do_eq_hovercard_qt_ data-mentionid_eq__qt_32589_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/profile/32589-patrickryan/_qt_ rel_eq__qt__qt__gt_@PatrickRyan_lt_/a_gt_ this is certainly a very interesting optimization problem and I am curious to hear what the actiongram team has to say. Regarding the “automatic” work flow_co_ there is a whole bunch of artistic knowledge still required (btw_co_ in envy).\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_strong_gt_Per Vertex I/O vs Computation_lt_/strong_gt__lt_br /_gt_\n\tAt this point I am wondering if the issue is web I/O or Computational strength. For example_co_ to get over the incredible file size of the vertex cache at 60fps_co_ I can imagine to trade in computational effort by _lt_a href_eq__qt_https_dd_//en.m.wikipedia.org/wiki/Curve_fitting_qt_ rel_eq__qt_external nofollow_qt__gt_curve fitting_lt_/a_gt_ the vertex positions in batches of 30pfs. It’s still a form of interpolation — but on a per vertex level. Leading to much greater flexibility.\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_img alt_eq__qt_Regression_pic_assymetrique.gif_qt_ class_eq__qt_ipsImage_qt_ height_eq__qt_460_qt_ src_eq__qt_https_dd_//upload.wikimedia.org/wikipedia/commons/a/a8/Regression_pic_assymetrique.gif_qt_ width_eq__qt_610_qt_ /_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\tTick data for stock &amp_sm_ trading applications is streamed in such a way.\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_b_gt_Stitching Multiple morph Animations (Phase-Function)_lt_/b_gt__lt_br /_gt_\n\tI believe the biggest issue with morph targets as a pla output is the limited resolution of just 4 targets. At this point I am wondering if it would be possible to come up with a smart pre-processor that slices the mesh and the timetimeline into multiple segments. I.e. into blobs of vertecies and 30fps. In the machine learning space_co_ this sounds a lot like a phase function CNN that is also used to reduce huge amounts of motion capture data into manageable and compatible chunks.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tThe advantage here is that no ratification is needed_co_ as one pla transpiration would just lead to an array of morph target sequences.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tNonetheless_co_ per vertex — instead of per mesh — interpolation would really be much more desired...\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"}]