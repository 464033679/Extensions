[{"Owner":"dbawel","Date":"2014-12-02T22:50:03Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_Hi Jeff_co__lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_I would avoid using .wav files if your medium is HTML 5.  Many users will have to install plugins depending on their OS and browser such as Microsoft Media Player and Quicktime_co_ and unless you have a script to check for plugins conditionally - which gets a bit messy - your .wav files won_t_t play.  I_t_ve read that many people are using .mp4 format_co_ however .mp4 is really an H.264 codec which is slow and often problematic depending on OS_co_ browser_co_ and browser version._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_I found a chart created a few months ago which provides a decent picture of what is supported in which OS and browser.  This is not a complete list_co_ so if you don_t_t find a format you want to use_co_ I might be able to provide additional info._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_Audio _lt_a href_eq__qt_http_dd_//html5doctor.com/multimedia-troubleshooting/#audio-support_qt_ rel_eq__qt_external nofollow_qt__gt_#_lt_/a_gt__lt_/p_gt__lt_ul_gt__lt_li_gt_Firefox supports Ogg Vorbis and WAV_lt_/li_gt__lt_li_gt_Opera supports Ogg Vorbis and WAV_lt_/li_gt__lt_li_gt_Safari supports MP3_co_ AAC_co_ and MP4_lt_/li_gt__lt_li_gt_Chrome supports Ogg Vorbis_co_ MP3_co_ WAV_co_ AAC_co_ and MP4_lt_/li_gt__lt_li_gt_Internet Explorer 9+ supports MP3_co_ AAC_co_ and MP4_lt_/li_gt__lt_li_gt_iOS supports MP3_co_ AAC_co_ and MP4_lt_/li_gt__lt_li_gt_Android supports AAC and MP3_lt_/li_gt__lt_/ul_gt__lt_p style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm__qt__gt_I prefer to use .mp3 files_co_ as I_t_ve found they are the most widely supported - although I decode them myself as many decoding applications are inefficient and .mp3 files often won_t_t work using the plethora of decoders out there.  .mp3 files are slow to load compared to .ogg files_co_ since there are several profiles that exist to load these - but seem to load more efficiently than .mp4 files.  .ogg files work under most circumstances and load quickly_co_ however they aren_t_t as universally supported on both desktops and mobile devices._lt_/p_gt__lt_p style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm__qt__gt_ _lt_/p_gt__lt_p style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm__qt__gt_I would be interested in hearing the opinion of the integrator of web audio into the BabylonJS framework_co_ and see what they have experienced.  Regardless_co_ for web audio in HTML 5_co_ my preference is .mp3 for it_t_s wide support.  But it all depends on your user base_co_ which will conform to whatever specs you provide as your character face tool is a valuable one.  I wish I could offer more_co_ but we_t_re still in our infancy developing in WebGL(I certainly am) - and my hat_t_s off to those who are writing the framework.  _lt_img src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/default_smile.png_qt_ alt_eq__qt__dd_)_qt_ srcset_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/smile@2x.png 2x_qt_ width_eq__qt_20_qt_ height_eq__qt_20_qt__gt__lt_/p_gt__lt_p style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm__qt__gt_ _lt_/p_gt__lt_p style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm__qt__gt_Cheers_co__lt_/p_gt__lt_p style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm__qt__gt_ _lt_/p_gt__lt_p style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm__qt__gt_David B._lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"JCPalmer","Date":"2014-12-03T15:20:14Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_David_co_ Thanks again.  Looking at your table &amp_sm_ source reference_co_ WAV &amp_sm_ MP3 also hits them all._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_It is missing one _qt_browser_qt_ I consider important_co_ CocoonJS. Values I see for it are based on being iOS or Android_dd__lt_/p_gt__lt_p_gt_CocoonJS on Android_dd_  WAV_co_ X-WAV_co_ Ogg Vorbis_lt_/p_gt__lt_p_gt_CocoonJS on iOS_dd_ MPEG_co_ MP4_co_ MP3_co_ X-WAV_co_ Ogg Vorbis_lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_Also of crucial importance is Web Audio support.  Right now I think Firefox_co_ &amp_sm_ Chrome are the only production players.  If anyone knows up to date info_co_ please share.  I wish a list of mandatory formats were part of that standard.  That would be the real controller of format.  The data we are listing here is for the &lt_sm_audio&gt_sm_ tag.  Think &lt_sm_audio&gt_sm_ might be too latent for this application. _lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_FYI_co_ CocoonJS Web Audio Canvas+ thread here_dd_  _lt_a href_eq__qt_http_dd_//support.ludei.com/hc/communities/public/questions/200566779-Accelerated-Canvas-Web-Audio-API-?locale_eq_en-us_qt_ rel_eq__qt_external nofollow_qt__gt_http_dd_//support.ludei.com/hc/communities/public/questions/200566779-Accelerated-Canvas-Web-Audio-API-?locale_eq_en-us_lt_/a_gt_ _lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_I am not as interested in their Webview+ container_co_ but looks like it works on iOS_dd_ _lt_a href_eq__qt_http_dd_//support.ludei.com/hc/communities/public/questions/201335185-When-will-Web-Audio-API-be-supported-?locale_eq_en-us_qt_ rel_eq__qt_external nofollow_qt__gt_http_dd_//support.ludei.com/hc/communities/public/questions/201335185-When-will-Web-Audio-API-be-supported-?locale_eq_en-us_lt_/a_gt__lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_I have seen _lt_strong_gt_libmp3lame.js_lt_/strong_gt_ that does .mp3_co_ but it is encoded as it is captured in a single step &amp_sm_ it is also huge.  Means you cannot do one recording_co_ then encode/save to multiple formats later._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_There are external converter programs as a backup_co_ though.  I_t_ll think about this a little more._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_Jeff_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"JCPalmer","Date":"2014-12-03T18:17:49Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_Nope_co_ I saw _lt_strong_gt_libmp3lame.js_lt_/strong_gt_ could be used with an in memory audio/wav Blob made as a first step_co_ but you need a worker thread.  WAV is so fast for the short files coming out of this that I was not using a worker.  The working example of this was also so slow.  MP3 encoding involves patenting / licensing issues._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_With a many different converters_co_ an online one _lt_a href_eq__qt_http_dd_//media.io/_qt_ rel_eq__qt_external nofollow_qt__gt_http_dd_//media.io/_lt_/a_gt_ _co_ there is no reason that I should clog this system up or expend my resources with multiple formats.  WAV is easy to make relative to lossy formats_co_ so it Rules!!  FYI_co_ I do have both stereo &amp_sm_ mono working._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_Jeff_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"dbawel","Date":"2014-12-03T21:30:46Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_Hi Jeff_co__lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_I_t_m learning a great deal from you in this post.  As for my preferences_co_ I use .mp3 files as they are compressed and WAV files are not.  But for small files_co_ .wav is the most widely supported format due to the fact it is not compressed audio.  You can always implement .mp3 and perhaps next gen formats at a later date when we hope most browsers adopt a standard - they almost have to in order to survive._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_MP3 files do not require licensing if for personal use_co_ however_co_ even if you license your facial animation application_co_ you_t_re not encoding which is done by the user of your application.  And for the user_co_ if what they produce is not for profit_co_ no one will ask for licensing from my experience.  However_co_ if someone does produce a game for profit with .mp3 audio tags_co_ they are required to pay a $2500 licensing fee - and if requested they must pay or face prosecution._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_If anyone wants to check for audio support in a browser_co_ here is a simple HTML 5 audio checker in Javascript_dd__lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(136_co_0_co_0)_sm__qt__gt_// returns a boolean_lt_/span_gt__lt_br_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_136)_sm__qt__gt_var_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_ audioTagSupport _lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt__eq__lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_ _lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt_!!_lt_/span_gt__lt_/p_gt__lt_p_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt_(_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_document_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt_._lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_createElement_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt_(_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_136_co_0)_sm__qt__gt__t_audio_t__lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt_)._lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_canPlayType_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt_)_sm__lt_/span_gt__lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_To check file compatibility_dd__lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(136_co_0_co_0)_sm__qt__gt_// Need to check the canPlayType first or an exception_lt_/span_gt__lt_br_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_    _lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(136_co_0_co_0)_sm__qt__gt_// will be thrown for those browsers that don_t_t support it      _lt_/span_gt__lt_br_gt__lt_br_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_    _lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_136)_sm__qt__gt_var_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_ myAudio _lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt__eq__lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_ document_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt_._lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_createElement_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt_(_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_136_co_0)_sm__qt__gt__t_audio_t__lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt_)_sm__lt_/span_gt__lt_br_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_   _lt_br_gt_    _lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_136)_sm__qt__gt_if_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_ _lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt_(_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_myAudio_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt_._lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_canPlayType_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt_)_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_ _lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt_{_lt_/span_gt__lt_br_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_     _lt_br_gt_       _lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(136_co_0_co_0)_sm__qt__gt_// Currently canPlayType(type) returns_dd_ _qt__qt__co_ _qt_maybe_qt_ or _qt_probably_qt_ _lt_/span_gt__lt_br_gt__lt_br_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_       _lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_136)_sm__qt__gt_var_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_ canPlayMp3 _lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt__eq__lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_ _lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt_!!_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_myAudio_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt_._lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_canPlayType _lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt_&amp_sm_&amp_sm__lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_ _lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_136_co_0)_sm__qt__gt__qt__qt__lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_ _lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt_!_eq__lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_myAudio_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt_._lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_canPlayType_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt_(_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_136_co_0)_sm__qt__gt__t_audio/mpeg_t__lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt_)_sm__lt_/span_gt__lt_br_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_       _lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_136)_sm__qt__gt_var_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_ canPlayOgg _lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt__eq__lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_ _lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt_!!_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_myAudio_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt_._lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_canPlayType _lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt_&amp_sm_&amp_sm__lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_ _lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_136_co_0)_sm__qt__gt__qt__qt__lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_ _lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt_!_eq__lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_myAudio_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt_._lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_canPlayType_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt_(_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_136_co_0)_sm__qt__gt__t_audio/ogg_sm_ codecs_eq__qt_vorbis_qt__t__lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt_)_sm__lt_/span_gt__lt_br_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_    _lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_102_co_0)_sm__qt__gt_}_lt_/span_gt__lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_And if you want to cover all bases_co_ I_t_m sure you_t_re familiar with implementing Flash as a fallback to audio support in browsers_co_ but or those who are not_co_ it_t_s quite simple._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_136)_sm__qt__gt_&lt_sm_audio _lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_0_co_102)_sm__qt__gt_controls_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_136)_sm__qt__gt_ _lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_0_co_102)_sm__qt__gt_preload_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_136)_sm__qt__gt__eq__lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_136_co_0)_sm__qt__gt__qt_auto_qt__lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_136)_sm__qt__gt_&gt_sm__lt_/span_gt__lt_br_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_  _lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_136)_sm__qt__gt_&lt_sm_source _lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_0_co_102)_sm__qt__gt_src_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_136)_sm__qt__gt__eq__lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_136_co_0)_sm__qt__gt__qt_elvis.mp3_qt__lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_136)_sm__qt__gt_ _lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_0_co_102)_sm__qt__gt_/_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_136)_sm__qt__gt_&gt_sm__lt_/span_gt__lt_br_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_  _lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_136)_sm__qt__gt_&lt_sm_source _lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_0_co_102)_sm__qt__gt_src_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_136)_sm__qt__gt__eq__lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_136_co_0)_sm__qt__gt__qt_elvis.ogg_qt__lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_136)_sm__qt__gt_ _lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(102_co_0_co_102)_sm__qt__gt_/_lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_136)_sm__qt__gt_&gt_sm__lt_/span_gt__lt_br_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_0)_sm__qt__gt_  _lt_/span_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(136_co_0_co_0)_sm__qt__gt_&lt_sm_!-- now include flash fall back --&gt_sm__lt_/span_gt__lt_br_gt__lt_span style_eq__qt_margin_dd_0px_sm_font-family_dd_inherit_sm_font-size_dd_inherit_sm_font-style_dd_inherit_sm_font-weight_dd_inherit_sm_color_dd_rgb(0_co_0_co_136)_sm__qt__gt_&lt_sm_/audio&gt_sm__lt_/span_gt__lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_I look forward to your next web application update._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_Cheers_co__lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_David B._lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"JCPalmer","Date":"2014-12-10T20:49:30Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_Well_co_ I just cannot seem to resolve the length of the recording.  It seems often that the recording stops before the sentence is finished.  Adding 500 ms padding just does not seem like the answer._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_Am also starting to look a the Audio classes.  I was wondering why the need to pass scene in the  Sound constructor?  It just gets its engine member.  Why not just make audioEngine a _lt_span style_eq__qt_font-size_dd_18px_sm__qt__gt__lt_strong_gt_public_lt_/strong_gt__lt_/span_gt_ static member of Engine?  Even if there could be multiple Engines in a _qt_VM_qt__co_ could they not share a instance of audioEngine?_lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_Seeing errors related to things things missing from mixins_dd_  AudioBufferSourceNode_co_ PannerNode_co_ AudioContext_co_ GainNode_co_ webkitAudioContext.  The mixins.ts I am using is  (parts I am not using are commented out / steal as desired)_dd__lt_/p_gt__lt_pre class_eq__qt_ipsCode prettyprint_qt__gt_interface Navigator {    isCocoonJS_dd_ boolean_sm_ // delete once using babylon.2.0.d.ts        getUserMedia(        options_dd_ { video?_dd_ boolean_sm_ audio?_dd_ boolean_sm_ }_co_         success_dd_ (stream_dd_ any) _eq_&gt_sm_ void_co_         error?_dd_ (error_dd_ string) _eq_&gt_sm_ void    ) _dd_ void_sm_        webkitGetUserMedia(        options_dd_ { video?_dd_ boolean_sm_ audio?_dd_ boolean_sm_ }_co_         success_dd_ (stream_dd_ any) _eq_&gt_sm_ void_co_         error?_dd_ (error_dd_ string) _eq_&gt_sm_ void    ) _dd_ void_sm_        mozGetUserMedia(        options_dd_ { video?_dd_ boolean_sm_ audio?_dd_ boolean_sm_ }_co_         success_dd_ (stream_dd_ any) _eq_&gt_sm_ void_co_         error?_dd_ (error_dd_ string) _eq_&gt_sm_ void    ) _dd_ void_sm_}interface Window {   AudioContext _dd_ AudioContext_sm_   webkitAudioContext _dd_ AudioContext_sm_}interface HTMLAnchorElement{    download _dd_ string_sm_}interface HTMLURL{    revokeObjectURL _dd_ (string) _eq_&gt_sm_ void_sm_}interface AudioContext {    new ()_dd_ any_sm_    destination _dd_ AudioDestinationNode_sm_    sampleRate _dd_ number_sm_    currentTime _dd_ number_sm_//    listener _dd_ AudioListener_sm_    state _dd_ AudioContextState_sm_    suspend ()_sm_    resume ()_sm_    close ()_sm_    onstatechange _dd_ () _eq_&gt_sm_ void_sm_    createBuffer (numberOfChannels _dd_ number_co_ length _dd_ number_co_ sampleRate _dd_ number) _dd_ AudioBuffer_sm_//    decodeAudioData (audioData _dd_ ArrayBuffer_co_ successCallback? _dd_ (decodedData _dd_ AudioBuffer) _eq_&gt_sm_ void_co_ errorCallback? _dd_ (DOMException _dd_ any) _eq_&gt_sm_ void) _dd_ AudioBuffer_sm_    createBufferSource () _dd_ AudioBufferSourceNode_sm_//    createMediaElementSource (mediaElement _dd_ HTMLMediaElement) _dd_ MediaElementAudioSourceNode_sm_    createMediaStreamSource (mediaStream _dd_ any) _dd_ MediaStreamAudioSourceNode_sm_//    createMediaStreamDestination () _dd_ MediaStreamAudioDestinationNode_sm_//    createAudioWorker (scriptURL _dd_ string_co_ numberOfInputChannels? _dd_ number_co_ numberOfOutputChannels? _dd_ number) _dd_ AudioWorkerNode_sm_    createScriptProcessor (bufferSize? _dd_ number_co_ numberOfInputChannels? _dd_ number _co_ numberOfOutputChannels? _dd_ number) _dd_ ScriptProcessorNode_sm_//    createAnalyser () _dd_ AnalyserNode_sm_    createGain () _dd_ GainNode_sm_//    createDelay (maxDelayTime? _dd_ number) _dd_ DelayNode_sm_//    createBiquadFilter () _dd_ BiquadFilterNode_sm_//    createWaveShaper () _dd_ WaveShaperNode_sm_//    createPanner () _dd_ PannerNode_sm_//    createStereoPanner () _dd_ StereoPannerNode_sm_//   createConvolver () _dd_ ConvolverNode_sm_//    createChannelSplitter (numberOfOutputs? _dd_ number) _dd_ ChannelSplitterNode_sm_//    createChannelMerger (numberOfInputs? _dd_ number ) _dd_ ChannelMergerNode_sm_//    createDynamicsCompressor () _dd_ DynamicsCompressorNode_sm_//    createOscillator () _dd_ OscillatorNode_sm_//    createPeriodicWave (real _dd_ Float32Array_co_ imag _dd_ Float32Array) _dd_ PeriodicWave_sm_}interface AudioBuffer {    sampleRate _dd_ number_sm_    length _dd_ number_sm_    duration _dd_ number_sm_    numberOfChannels _dd_ number_sm_    getChannelData (channel _dd_ number) _dd_ Float32Array_sm_    copyFromChannel (destination _dd_ Float32Array_co_ channelNumber _dd_ number_co_ startInChannel? _dd_ number) _dd_ void_sm_    copyToChannel (source _dd_ Float32Array_co_ channelNumber _dd_ number_co_ startInChannel? _dd_ number) _dd_ void_sm_}enum AudioContextState {    _qt_suspended_qt__co_    _qt_running_qt__co_    _qt_closed_qt_}interface AudioNode  {    connect (destination _dd_ AudioNode_co_ output? _dd_ number_co_ input? _dd_ number) _dd_ void_sm_    connect (destination _dd_ AudioParam_co_ output? _dd_ number) _dd_ void_sm_    disconnect (output? _dd_ number) _dd_ void_sm_    context _dd_ AudioContext_sm_    numberOfInputs _dd_ number_sm_    numberOfOutputs _dd_ number_sm_    channelCount _dd_ number_sm_    channelCountMode _dd_ number_sm_    channelInterpretation _dd_ any_sm_}interface GainNode extends AudioNode {    gain _dd_ AudioParam_sm_}interface AudioDestinationNode extends AudioNode {    maxChannelCount _dd_ number_sm_}interface ScriptProcessorNode extends AudioNode {    onaudioprocess_dd_ (any) _eq_&gt_sm_ void_sm_    bufferSize _dd_ number_sm_}interface AudioBufferSourceNode extends AudioNode {    buffer _dd_ AudioBuffer_sm_    playbackRate _dd_ AudioParam_sm_    detune _dd_ AudioParam_sm_    loop _dd_ boolean_sm_    loopStart _dd_ number_sm_    loopEnd _dd_ number_sm_        start (when? _dd_ number_co_  offset? _dd_ number_co_ duration? _dd_ number) _dd_ void_sm_    stop (when? _dd_ number) _dd_void_sm_    onended _dd_ any_sm_}interface MediaStreamAudioSourceNode extends AudioNode {}interface AudioParam {    value _dd_ number_sm_    defaultValue _dd_ number_sm_    setValueAtTime (value _dd_ number_co_ startTime _dd_ number) _dd_ void_sm_    linearRampToValueAtTime (value _dd_ number_co_ endTime _dd_ number) _dd_ void_sm_    exponentialRampToValueAtTime (value _dd_ number_co_ endTime _dd_ number) _dd_ void_sm_    setTargetAtTime (target _dd_ number_co_ startTime _dd_ number_co_ timeConstant _dd_ number) _dd_ void_sm_    setValueCurveAtTime (values _dd_ Float32Array_co_ startTime _dd_ number_co_ duration _dd_ number) _dd_ void_sm_    cancelScheduledValues (startTime _dd_ number) _dd_ void_sm_}/*interface AudioWorkerNode extends AudioNode {    terminate () _dd_ void_sm_    postMessage (message _dd_ string_co_ transfer? _dd_ any) _dd_ void_sm_                attribute EventHandler onmessage_sm_    addParameter (DOMString name_co_ optional float defaultValue) _dd_ AudioParam_sm_    void       removeParameter (DOMString name)_sm_} */_lt_/pre_gt__lt_p_gt_also unrelated mixins missing for DebugLayer in scene_co_ HTMLElement.src in videoTexture_co_ _lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_plus compile errors in Mesh.applyDisplacementMap_co_ Mesh.CreateGroundFromHeightMap_co_ &amp_sm_ BabylonFileLoader.parshMesh._lt_/p_gt__lt_p_gt_Errors in tools &amp_sm_ database too.  Gulp seems to be quite slack if it is letting this stuff through._lt_/p_gt__lt_p_gt_ _lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"Deltakosh","Date":"2014-12-10T22:22:22Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_I added the missing waa.d.ts to support WebAudio interfaces._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_I let Davrous answer your questions about WebAudio architecture._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_About compile errors_dd_ are they still here even with the waa.d.ts file?_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"davrous","Date":"2014-12-11T12:39:52Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_Hello_co__lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_ My idea for Web Audio is to add sounds to a scene_co_ this scene will be able to have multiple tracks. In this way_co_ you will be able to apply effects_co_ volume on a dedicated track. I then need to keep references to the sound being added to a scene. I will also let the user instantiate a sound without affecting it to a scene if needed._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_ For the codec support_co_ we will only offer that the browser is offering. For instance_co_ let_t_s imagine that .wav &amp_sm_ .mp3 is supported by IE_co_ Firefox &amp_sm_ Chrome but .ogg is not supported by IE_co_ it will be up to the developer of the game to use .mp3 or .wav assets to assume cross-browsers compatibility. Supporting codec via JavaScript libraries is not in our scope at all for several reasons_dd_ performance first and royalties/patent potential problems. We will then stick to the pure browsers support. _lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_ I_t_m just in the very beginning of the Web Audio Babylon.js architecture. If you have ideas on how it should be implemented_co_ I_t_m open to suggestions_co_ even if I_t_ve already have a pretty good idea on how I_t_d like to implement it. _lt_img src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/default_wink.png_qt_ alt_eq__qt__sm_)_qt_ srcset_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/wink@2x.png 2x_qt_ width_eq__qt_20_qt_ height_eq__qt_20_qt__gt__lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_David_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"JCPalmer","Date":"2014-12-11T16:04:49Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_First_co_ yes the waa.d.ts did solve all the syntax issues  (also means I can ditch all my non-recording related mixins _lt_img src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/default_smile.png_qt_ alt_eq__qt__dd_)_qt_ srcset_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/smile@2x.png 2x_qt_ width_eq__qt_20_qt_ height_eq__qt_20_qt__gt_ ).  I do not know why it did_co_ since some stuff had nothing to do with audio.  Theory_dd_  The audio error caused failures later_co_ so new stuff did not compile.  Anyway_co_ fixed._lt_/p_gt__lt_p_gt_- - - - - - - - - -_lt_/p_gt__lt_p_gt_As far as API_co_ having sounds being members  of  (catalogued by) scene is fine_co_ but grabbing the BABYLON.AudioEngine using the BABYLON.Scene means it cannot be an optional arg.  I have restructured my proof of concept into an implementation such that I have a MORPH.Sentence class whose constructor parses my _qt_Arpabet+_qt_ string into a MORPH.EventSeries of facial MORPH.Deformations.  After looking at your BABYLON.Sound class_co_ I was thinking of  making MORPH.Sentence a subclass of it.  This would give a very tight integration of the sound to the vertex repositioning directions_co_ and simplify initiating them_co_ by overriding the play() method._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_These MORPH.Sentences could be constructed independent of knowledge of the actual MORPH.Mesh  ( or maybe a MORPH.MakeHuman subclass _lt_img src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/default_wink.png_qt_ alt_eq__qt__sm_)_qt_ srcset_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/wink@2x.png 2x_qt_ width_eq__qt_20_qt_ height_eq__qt_20_qt__gt_ ).  I have not figured out what to do after that yet_co_ but that mandatory BABYLON.Scene arg is making me nervous.  I want to have an architecture where everything is OO oriented around a mesh instance_co_ not standalone sub-systems._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_I do not see a need for more than one instance of BABYLON.AudioEngine.  Using the Engines would make my starting of navigator.getUserMedia for recording much less complicated.  I would like to ditch my code for instancing an AudioEngine.  I could call getAudioEngine() on my engine instance_co_ but prefer to call a static Engine.getAudioEngine()_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"JCPalmer","Date":"2014-12-11T18:40:40Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_One other thing too_co_ could url be optional in the constructor as well?  You could just do nothing in that case_co_ leaving _isReadyToPlay _eq_ false.  In order to use BABYLON.Sound for playback in the recording app_co_ I would have a method in the sub-class_co_ which had a _lt_strike_gt__soundSource_lt_/strike_gt_ _audioBuffer passed in as an arg._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_During the recording process_co_ the constructor would have already been run.  Also_co_ the .wav file is not written every record.  Want to give the operator the chance to playback with both the movement &amp_sm_ sound_co_ to decide if it is right._lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"davrous","Date":"2014-12-11T21:07:29Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_Yes_co_ it is planned to build a sound using directly an audioBuffer in order to use it with the Assets Manager for instance. I will have a look to your architecture request. If it can help you building your speech solution_co_ will do._lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"JCPalmer","Date":"2014-12-11T21:46:36Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_Thanks_co_  I just pushed version 1.1 up to the repository_co_ then switched out my mixins.ts stuff for waa.d.ts.  Not really perfect_co_ but wanted a snapshot with 1.14_co_ before trying to integrate with 2.0.  Needed to get commit points anyway_co_ since it had been about 2 months._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_Will put out an updated link_co_ once looking good._lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"dbawel","Date":"2014-12-15T05:50:41Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_Hi Jeff_co__lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_Can you post your updated mixins.ts file?  I_t_d like to better understand what was happening_co_ and why some of the compile errors you mentioned were apparently solved by waa.d.ts._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_Thanks_co__lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_David B._lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"JCPalmer","Date":"2014-12-15T16:48:39Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_David_co__lt_/p_gt__lt_p_gt_The entire MORPH 1.1 is published_co_ so you can look at almost anything you want. _lt_a href_eq__qt_https_dd_//github.com/BabylonJS/Extensions/tree/master/Morph_qt_ rel_eq__qt_external nofollow_qt__gt_https_dd_//github.com/BabylonJS/Extensions/tree/master/Morph_lt_/a_gt_ .  The one thing not in the repository the is cmudict.0.7a.js_co_  (but .java &amp_sm_ .class files that build it are).  Too big_co_ and I also do not want to give the impression you need it for anything other than recording._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_The compile issues were actually in the Babylon.JS repository_co_ not in my code in the extensions respository.  There the problem was they were not defining the web audio functions anywhere.  The Typescript plug-in I use_co_ was erroring due to this.  It was also not recognizing other new stuff.  When I pulled the Babylon.js repository with waa.d.ts_co_ all the web audio reference were found.  The plug-in also then was ok with unrelated files.  Think this is a plug-in phenomenon.  I now use waa.d.ts too_co_ and ripped those definitions out of mixins.ts.  No need to re-invent the wheel._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_I am now waiting on the Babylon audio implementation &amp_sm_ Make Human 1.2_co_ so I am stopping this for now.  I have updated the page behind the link with the voice recorder. (For some reason on my linux system_co_ playback does not show any Voice_co_ but it did save hear able .wav files).  Here it is again _dd__lt_/p_gt__lt_p_gt__lt_a href_eq__qt_https_dd_//googledrive.com/host/0B6-s6ZjHyEwUSDVBUGpHOXdtbHc_qt_ rel_eq__qt_external nofollow_qt__gt_https_dd_//googledrive.com/host/0B6-s6ZjHyEwUSDVBUGpHOXdtbHc_lt_/a_gt__lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_These are the changes since last publish_dd__lt_/p_gt__lt_p_gt_- writes mono .wav files_co_ if asked_lt_/p_gt__lt_p_gt_- the arpabet no longer show vowel stresses (still in cmudict.0.7a.js though)_lt_/p_gt__lt_p_gt_- Switched the arpabet separator character from _t_ _t_ to _t___t__lt_/p_gt__lt_p_gt_- the arpabet which actually run is in an editable text control_co_ so now it can be copied to / pasted from the clipboard_lt_/p_gt__lt_p_gt_- the keyboard direction keys no longer move the mesh_co_ which was annoying_lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_Also have implemented what I call Arpabet+_co_ which incorporates the data from the sliders into the string.  This means expressions can be encoded with speech.  The CENSORED expression_co_ you have to add manually like _lt_strong_gt_F^2!1+3_AH#_K#_._Y_UW_._AE_S_HH#_OW_L_.#_lt_/strong_gt_  .  I am not sure how important censoring is_co_ but is does show the problem syncing the voice with the mesh deformations.  It is fine when played Ignoring Censoring_co_ but somehow when silencing certain sections of audio_co_ things run late.  I think this also related to having to pad the recording with 500 milli-seconds to keep it from being cut off (The important problem)._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_Internally_co_ I no longer have a monolithic Voice class.  Have modularized into a Sentence class_co_ which will be a subclass of BABYLON.Sound_co_ when it is done.  There is still a small Voice class_co_ but that is likely to be integrated into a future MORPH.Mesh subclass._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_Jeff_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"JCPalmer","Date":"2014-12-15T16:57:09Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_As a separate note_co_ Make Human 1.1 is to have facial bones to implement expressions.  They say this was for consistency.  I think the 1.2 release will have the Blender MHX plugin turning this back into shapekeys_co_ but not totally clear_co_ based on scant into.  If it stays as bones_co_ I am going to have to learn how to build shapekeys in python_co_ not just export shapekeys to Babylon.JS._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_FYI_co_ I saw a fixed bug that had an interesting picture which shows the bones. _lt_a href_eq__qt_http_dd_//bugtracker.makehuman.org/issues/637_qt_ rel_eq__qt_external nofollow_qt__gt_http_dd_//bugtracker.makehuman.org/issues/637_lt_/a_gt__lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"dbawel","Date":"2014-12-15T21:25:40Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_Hi Jeff_co__lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_Thanks for the link.  I ran a couple of searches yesterday on GitHub_co_ but I found no results under your GDF name - or other indicators I tried.  I_t_m still not sure why you weren_t_t able to reference Web Audio correctly with your use of mixins - but as you stated_co_ _t_no need to re-invent the wheel._t_  However_co_ I_t_d still like to understand more specifically where mixins failed as this might be an issue in referencing yet unknown components in the future. _lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_Do you think that your audio recording issue might be hardware / OS related_co_ since in reviewing your scripts and structure I cannot see why a delay is required for recording - especially such a long delay.  I might only expect such a problem if you weren_t_t recording locally - but if this was the case_co_ I doubt 500 ms would solve the resulting truncated audio files you_t_re finding_co_ as this would be too inconsistent to manage effectively.  So_co_ it would be valuable to understand causality in this case._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_Everyone has their preferences_co_ but most people would agree with you that using morph targets provide far better results for your application.  As you know_co_ bones introduce rigidity into muscular animation_co_ and the results are far less pliable in performance - as well as limiting vertex ROM (range of motion) and polymorphic influence.  The time required in rigging and enveloping bones is also comparatively prohibitive_co_ and ultimately introduce not only transform limitations_co_ but compatibility issues with other functions and attributes.  Bones are also less efficient in computation._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_Will you be introducing an envelope or similar gait to match duration of the sum (or subset) of an animation to the length of an audio waveform?  If you are familiar with how Flash syncs audio and facial_co_ they implemented the most basic fit function possible_co_ however the result is somewhat acceptable.  You might also implement a function to identify basic waveform peak analysis for the voice recording_co_ which is a simple way to set pointers for key morph targets and their specific duration and attenuation. _lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_Thanks for your continued development on this.  I_t_m not yet certain how your _qt_censored_qt_ controls will ultimately contribute to overall quality and usability_co_ but it_t_s certainly an interesting attribute.  It_t_s great to see someone thinking outside of the box._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_Cheers_co__lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_David B._lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"JCPalmer","Date":"2014-12-15T23:03:08Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_Mixin wise_co_ I never have had a problem.  I was / am using a version of Babylon 2.0 that is pre-audio.  My mixins.ts worked perfectly.  I just stopped using my own_co_ when I found they are officially published.  I was only commenting of the state of the BabylonJS repository right after they first started adding audio._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_Using shape keys / morph targets is more than a preference in the case of BJS.  There is no bone interpolator_co_ just playing of pre-built animations developed externally_co_ like in Blender_co_ then exported.  That means you would be stuck with lip-syncing_co_ not voice-syncing._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_I am afraid I do not even know what _qt_basic waveform peak analysis_qt_ is.  I have never used flash.  I am mostly just making this up as I go along.  Sometimes this produces unexpected results.  My thought on censored_co_ if useful at all_co_ is to come with something that might be a requirement of the iOS or GooglePlay stores.  Those developer agreements are massive._lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"dbawel","Date":"2014-12-16T01:15:42Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_Hi Jeff_co__lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_I had assumed you were already using AnalyserNodes to identify peaks in your audio file_co_ and hopefully would eventually run limited spectrum analysis as well - until I reviewed your code - which is why I asked if you planned on implementing this in the near future when I didn_t_t find any reference to these in a doc search.  Access to these are available in the Web Audio API_co_ and are essential to lip sync and animation quality.  I_t_m sure once you implement AnalyserNodes into your application_co_ it will solve most sync issues and dramatically improve performance and quality of animation - well beyond practically anything else you might implement.  I cannot imagine developing an application such as what you_t_re building without making AnalyserNodes a key element in many functions.  Instead of me explaining this (and more) in detail_co_ here is a very good reference on the use of AnalyserNodes_co_ their function_co_ and how to implement them into your Javascript_dd__lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt__lt_a href_eq__qt_http_dd_//chimera.labs.oreilly.com/books/1234000001552/ch05.html_qt_ rel_eq__qt_external nofollow_qt__gt_http_dd_//chimera.labs.oreilly.com/books/1234000001552/ch05.html_lt_/a_gt__lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_Your work is about to become allot easier and these will provide a much better result. _lt_img src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/default_biggrin.png_qt_ alt_eq__qt__dd_D_qt_ srcset_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/biggrin@2x.png 2x_qt_ width_eq__qt_20_qt_ height_eq__qt_20_qt__gt_  However_co_ as few people have experience in audio engineering_co_ let me know if there is anything I might explain if it_t_s not clear conceptually or otherwise._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_A quick note on developer rights - my company is in the middle of trying to fully understand the licensing requirements in using H.265_co_ as this format is being adopted by most all device manufacturers and application developers.  Within one year_co_ H.265 will replace H.264 and is expected to be the most widely used format for streaming video and audio worldwide.  So as difficult as it is to understand the ramifications of following the guidelines when using other people_t_s IP_co_ everyone should follow your lead and fully understand licensing and usage for any external IP they implement_sm_ otherwise_co_ they might find themselves with a cease and desist order against them - having spent years building their application_co_ game_co_ etc. - just to find themselves with a product they cannot legally release or afford to release._lt_/p_gt__lt_p_gt_And for anyone considering supporting H.265_co_ be aware that anything published for profit or not_co_ is subject to giving up their rights to the property (content) once it is displayed (published) using the H.265 format.  However_co_ it will become the standard_co_ and it is by far the highest quality and most efficient compression algorithm for streaming video (4K) and audio with interactive events natively.  You Tube has yet to announce any support for H.265_co_ yet the rest of the industry is moving quickly towards this format.  Unfortunately_co_ since Google owns the VP9 format_co_ they are forcing You Tube away from H.265.  But irregardless of which format is supported_co_ most people publishing content to You Tube will never read their licensing agreement which generally and broadly gives away rights to the content they are publishing.  I don_t_t hear much noise about licensing rights these days_co_ however I_t_m guessing we all will be discussing this extensively in the near future._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_Let me know if I can assist or advise in any way to help you get your lip syncing and facial application to release.  You_t_ve laid a very good foundation_co_ and I_t_m guessing your development and quality of output will advance dramatically moving forward._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_Cheers_co__lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_David B_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"JCPalmer","Date":"2015-01-24T18:51:24Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_Was wondering if a public set of an audioBuffer can be added to Sound for sub-classing.  Will not be known at construction_co_ and just came from a mic_co_ so no decoding is required.  Can always pass some dummy arg to avoid error in call to super in constructor.  Something like_dd__lt_/p_gt__lt_pre class_eq__qt_ipsCode prettyprint_qt__gt_        public setAudioBuffer(audioBuffer _dd_ AudioBuffer) _dd_ void{            this._audioBuffer _eq_ audioBuffer_sm_            this._isReadyToPlay _eq_ true_sm_        }_lt_/pre_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"davrous","Date":"2015-01-24T22:15:16Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_This is indeed a good idea. I_t_ll work on adding that. _lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"pathogen","Date":"2015-07-02T15:44:55Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_Wow! Fantastic project JCPalmer! And the amount of knowledge in this thread is incredible. It is making my 3_dd_37am brain overflow with ideas _lt_img src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/default_laugh.png_qt_ alt_eq__qt__dd_lol_dd__qt__gt__lt_br_gt__lt_br_gt_davrous_dd_ have you seen _lt_a href_eq__qt_https_dd_//github.com/TONEnoTONE/Tone.js/_qt_ rel_eq__qt_external nofollow_qt__gt_Tone.js_lt_/a_gt_? It_t_s written in typescript_co_ and has a really ingenious oscillator based clock which evades javascript_t_s poor clock timing entirely._lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"dbawel","Date":"2015-07-03T02:12:53Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_Hi pathogen_co__lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_I hadn_t_t seen Tone.js before.  Interesting API.  It_t_s early in development_co_ but looks promising.  I_t_ve been speaking alot about Intel_t_s XDK lately_co_ as it certainly is developing rapidly_co_ and of course_co_ they have the resources to grow quickly.  It_t_s really good for integrating devices into your applications_co_ and has audio and video integration tools such as basic facial recognition_co_ respiratory rates_co_ and audio recognition - although still in it_t_s early forms currently. But this opens the door to fully automate facial animation and speech recognition paired together for the first time._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_There_t_s lots of tools on the horizon_co_ and many are promising.  These days_co_ there_t_s almost too many to choose from - but that I suppose is a good thing.  Thanks for the heads up_co_ and I look forward to Jeff_t_s next version for speech and facial animation._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_As for JCPalmer_t_s question regarding waveform peak analysis (I should have responded to this months ago)_co_ it_t_s a good method of detecting and discriminating the progression of audio signals by analising _qt_signal energy present_qt_ and _qt_signal energy absense_qt_ in specific frequencies of human speech - and ignoring patterns (cadence) which is inconsistant from person to person and by age.  Thus by measuring frequencies within the range of 1K to 5K_co_ this information can be used to reliably identify phonemes providing you ignore the patterns of peaks and the duration of signal on and signal off intervals.   However_co_ these frequencies are generally consistant in almost all human speech - regardless of language and dialect. So this is what I use for most real-time speech analysis as it is very quick to provide reasonably accurate results to drive morph targets for a list of phonemes of around 12 to 15 targets for a _qt_human_qt_ mouth and tounge - which the tounge is typically overlooked but a very important element of human speech.  Most recently_co_ I wrote a plugin for Motionbuilder to isolate audio frequencies and to analize the resulting audio to drive animatronic servos which shaped the mouth of the _qt_Scribe_qt_ goblin and other goblins for the film _qt_The Hobbit._qt_  If you watch the goblin characters in the first film_co_ the speech was driven in real time using waveform peak analysis_co_ while I puppeteered the non speech facial emotions using custom _qt_joystick_qt_ controllers in real time and on the film set. This allowed Pete J. to direct the actors naturally as they spoke into a microphone which I then delayed the audio by about 3 miliseconds which is the time required to analize the audio peaks and sync the audio signal to the physical servos driving both the silicon model as well as digital puppet characters._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_So if you watch the film_co_ the speech appears very natural with just a limited list of phonemes - although a much longer list of _qt_virtual_qt_ morph targets does not introduce any additional delays. Compare this to the completely manual puppets from the Star Wars films which the resulting animation was absolute crap comparitively - not that my work is comparable in any way_co_ as I simply set up a process with tools that weren_t_t readily available to Stan Winston at the time. This process is now completely digital prior to controlling the voltage to the animatronic servos_co_ and could be applied as an extension for Babylon.js to drive speech and facial animation in real time to practically any character_t_s facial morph targets for almost any application or game.  It just takes a brilliant mind such as JCPalmer_t_s to efficiently write the code to pass the waveform peak analysis _qt_WPA_qt_ from a microphone (and camera if desired for facial emotions such as happy_co_ sad_co_ surprise_co_ etc.) to drive a morph target list with some simple math I could assist with if requested.  I might also be able to provide someone developing an extension for Babylon.js some Motionbuilder scenes that are completely digital_co_ to drive digitally rendered models instead of animatronic servos.  I just have to use some discretion as all of the models are the property of companies such as Dreamworks and New Line._lt_/p_gt__lt_p_gt_ _lt_/p_gt__lt_p_gt_So utilizing an extension such as Web Audio_co_ WPA would be my personal choice for real time speech analysis avoiding the many methods I_t_ve seen and also personally applied_co_ which in my opinion_co_ over complicate the process which has been repeatedly proven in formats from video games to 50 foot faces on cinema screens in high resolution. I know this doesn_t_t begin to explain the math driving the process_co_ but the tools appear to be in place to make this process reasonably simple to apply._lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"}]