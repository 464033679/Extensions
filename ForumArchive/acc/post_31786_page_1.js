[{"Owner":"fenomas","Date":"2017-07-21T07:23:40Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tHi_co_\n_lt_/p_gt_\n\n_lt_p_gt_\n\tI have a scene with around ~800 non-static meshes moving around_co_ and I find the main performance bottleneck is the time taken by Babylon calling _lt_strong_gt_evaluateActiveMeshes_lt_/strong_gt__co_ which in turn calls _lt_strong_gt_computeWorldMatrix_lt_/strong_gt_ and _lt_strong_gt__updateBoundingInfo_lt_/strong_gt_ on most of the meshes.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tHowever_co_ the nature of my scene is that most of the meshes never rotate_co_ and I separately track their locations and bounding info. So in principle_co_ it seems like I could tell Babylon they_t_re static (by calling freezeWorldMatrix?)_co_ and then manually update their boundingInfo objects_co_ and set their worldMatrices to simple translation matrices.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tWould this be a safe approach_co_ or has anyone tried it? Or is there some built-in way of achieving a similar result? Or does freezing the world matrix have other implications that would cause this to break?\n_lt_/p_gt_\n\n_lt_p_gt_\n\tThanks!\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"jerome","Date":"2017-07-21T08:30:14Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tmmmmh... I_t_m afraid you can_t_t skip the WorldMatrix computation that easily because this matrix is passed to the GPU so as it can compute all the mesh vertices final positions and then all the projections to the screen.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tComputing your own WM from a simple translation matrix (+freezing it) should work either. It_t_s worth a try... not sure the gain is really high though because computing 800 quaternions (for the complete WM) is really fast actually. \n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_em_gt_updateBoundingInfo()_lt_/em_gt_ should be quite fast also as it updates only the 8 bounding box vertex positions (+ the bbox center). You can update your own bInfo and then lock it to skip the automatic computation with _dd_ _lt_a href_eq__qt_http_dd_//doc.babylonjs.com/classes/3.0/boundinginfo#islocked-boolean_qt_ rel_eq__qt_external nofollow_qt__gt_http_dd_//doc.babylonjs.com/classes/3.0/boundinginfo#islocked-boolean_lt_/a_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\tUsually_co_ _lt_em_gt_evaluateActiveMeshes()_lt_/em_gt_ spends most of the time in the call of _lt_em_gt_isInFrustum()_lt_/em_gt_ _dd_ culling\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_em_gt_btw_co_ I tried some weeks ago to implement a faster culling algo but I wasn_t_t satisfied by the results _dd_ _lt_a href_eq__qt_http_dd_//jerome.bousquie.fr/BJS/test/frustum.html_qt_ rel_eq__qt_external nofollow_qt__gt_http_dd_//jerome.bousquie.fr/BJS/test/frustum.html_lt_/a_gt__lt_/em_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_em_gt_(fast duration _eq_ experimental algo_co_ frustum duration _eq_ legacy algo)  _lt_/em_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\t \n_lt_/p_gt_\n\n_lt_p_gt_\n\tIf you_t_re sure (I_t_m pretty sure you are because I know you_t_re a profiler pro) that the time is spent in the WorldMatrix and bInfo computations_co_ maybe you might think to other approaches _dd_ check if you can compute some logical pre-culling (so set some meshes as inactive from your game logic before the camera has to evaluate them)_co_ freeze/unfreeze the world matrix in turn for the meshes you know they didn_t_t move for some frames_co_ force the selection for the meshes you know they_t_re quite always in the frustum_co_ etc\n_lt_/p_gt_\n\n_lt_p_gt_\n\tMaybe using a SPS holding all these meshes (or most of them_co_ even if it_t_s a different model for each solid particle) could help as the SPS computes only one WM and each particle bInfo within the particle loop (so faster)... but has a global level culling (so less accurate _dd_ all the particles or none are culled). Usually one draw call_co_ even with false positives (things passed to the GPU that won_t_t be finally rendered because out of the screen)_co_ is faster than more pre-computations.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tThis must be tested on your very specific case to check what could be the best solution.\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"haestflod","Date":"2017-07-21T14:12:56Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t_lt_p_gt_\n\tHave you tried using octrees? I also had 800+ meshes in my scene and octrees helped my CPU performance by a lot.\n_lt_/p_gt_\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"fenomas","Date":"2017-07-22T04:47:57Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_blockquote class_eq__qt_ipsQuote_qt_ data-ipsquote_eq__qt__qt_ data-ipsquote-contentapp_eq__qt_forums_qt_ data-ipsquote-contentclass_eq__qt_forums_Topic_qt_ data-ipsquote-contentcommentid_eq__qt_182580_qt_ data-ipsquote-contentid_eq__qt_31786_qt_ data-ipsquote-contenttype_eq__qt_forums_qt_ data-ipsquote-timestamp_eq__qt_1500625814_qt_ data-ipsquote-userid_eq__qt_5453_qt_ data-ipsquote-username_eq__qt_jerome_qt__gt_\n\t_lt_div class_eq__qt_ipsQuote_citation_qt__gt_\n\t\t20 hours ago_co_ jerome said_dd_\n\t_lt_/div_gt_\n\n\t_lt_div class_eq__qt_ipsQuote_contents_qt__gt_\n\t\t_lt_p_gt_\n\t\t\tnot sure the gain is really high though because computing 800 quaternions (for the complete WM) is really fast actually.\n\t\t_lt_/p_gt_\n\t_lt_/div_gt_\n_lt_/blockquote_gt_\n\n_lt_p_gt_\n\tThis was my expectation as well_co_ but for scenes with lots of simple meshes it seems to be the bottleneck_co_ by a long shot.\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_a href_eq__qt_http_dd_//www.babylonjs-playground.com/#E2HVNG_qt_ rel_eq__qt_external nofollow_qt__gt_Here_t_s_lt_/a_gt_ a simple pg that demonstrates roughly what I_t_m talking about - for me_co_ profiling that shows that about 50% of the total scripting time is spent inside computeWorldMatrix.\n_lt_/p_gt_\n\n_lt_p_gt_\n\t(Profiling in the playground is iffy_co_ but if you load that link and profile it without changing anything_co_ nothing should get deopted so it should be fine.)\n_lt_/p_gt_\n\n_lt_blockquote class_eq__qt_ipsQuote_qt_ data-ipsquote_eq__qt__qt_ data-ipsquote-contentapp_eq__qt_forums_qt_ data-ipsquote-contentclass_eq__qt_forums_Topic_qt_ data-ipsquote-contentcommentid_eq__qt_182607_qt_ data-ipsquote-contentid_eq__qt_31786_qt_ data-ipsquote-contenttype_eq__qt_forums_qt_ data-ipsquote-timestamp_eq__qt_1500646376_qt_ data-ipsquote-userid_eq__qt_22760_qt_ data-ipsquote-username_eq__qt_haestflod_qt__gt_\n\t_lt_div class_eq__qt_ipsQuote_citation_qt__gt_\n\t\t14 hours ago_co_ haestflod said_dd_\n\t_lt_/div_gt_\n\n\t_lt_div class_eq__qt_ipsQuote_contents_qt__gt_\n\t\t_lt_p_gt_\n\t\t\tHave you tried using octrees? I also had 800+ meshes in my scene and octrees helped my CPU performance by a lot.\n\t\t_lt_/p_gt_\n\t_lt_/div_gt_\n_lt_/blockquote_gt_\n\n_lt_p_gt_\n\tI am using Octrees - performance is better with them than without them_co_ but computeWorldMatrix is still the biggest bottleneck either way.\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"jerome","Date":"2017-07-22T07:25:23Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tNot sure the octrees are a good option when the meshes move in the World.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tThe profiler says what you say... I will have a look at the reason why computeWorldMatrix() spends this time weirdly\n_lt_/p_gt_\n\n_lt_p_gt_\n\t[EDIT] when displaying the profile results as a tree (topdown)_co_ the percentage of the time used by computeWorldMatrix() while 7200 ms is _qt_only_qt_  37% of the total time for me ... what still seems a high ratio imho\n_lt_/p_gt_\n\n_lt_table style_eq__qt_color_dd_#303942_sm__qt__gt__lt_tbody_gt__lt_tr_gt__lt_td_gt_\n\t\t\t\t \n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t \n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t_lt_p_gt_\n\t\t\t\t\t \n\t\t\t\t_lt_/p_gt_\n\t\t\t_lt_/td_gt_\n\t\t_lt_/tr_gt__lt_/tbody_gt__lt_/table_gt__lt_table style_eq__qt_color_dd_#303942_sm__qt__gt__lt_tbody_gt__lt_tr style_eq__qt_color_dd_#FFFFFF_sm__qt__gt__lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span style_eq__qt_color_dd_inherit_sm__qt__gt_226.6 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_inherit_sm__qt__gt_6.34 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span style_eq__qt_color_dd_inherit_sm__qt__gt_1322.5 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_inherit_sm__qt__gt_36.99 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\ti.computeWorldMatrix_lt_span style_eq__qt_color_dd_#FFFFFF_sm__qt__gt_babylon.js_dd_7_lt_/span_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t \n\t\t\t_lt_/td_gt_\n\t\t_lt_/tr_gt__lt_tr_gt__lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span_gt_101.3 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_#999999_sm__qt__gt_2.83 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span_gt_198.7 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_#999999_sm__qt__gt_5.56 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\tt.isSynchronized_lt_span style_eq__qt_color_dd_#808080_sm__qt__gt_babylon.js_dd_6_lt_/span_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t \n\t\t\t_lt_/td_gt_\n\t\t_lt_/tr_gt__lt_tr_gt__lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span_gt_80.6 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_#999999_sm__qt__gt_2.25 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span_gt_370.1 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_#999999_sm__qt__gt_10.35 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\tt.multiplyToRef_lt_span style_eq__qt_color_dd_#808080_sm__qt__gt_babylon.js_dd_2_lt_/span_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t \n\t\t\t_lt_/td_gt_\n\t\t_lt_/tr_gt__lt_tr_gt__lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span_gt_48.2 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_#999999_sm__qt__gt_1.35 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span_gt_48.2 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_#999999_sm__qt__gt_1.35 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\tt.copyFrom_lt_span style_eq__qt_color_dd_#808080_sm__qt__gt_babylon.js_dd_2_lt_/span_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t \n\t\t\t_lt_/td_gt_\n\t\t_lt_/tr_gt__lt_tr_gt__lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span_gt_31.4 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_#999999_sm__qt__gt_0.88 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span_gt_31.4 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_#999999_sm__qt__gt_0.88 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\ti.copyFrom_lt_span style_eq__qt_color_dd_#808080_sm__qt__gt_babylon.js_dd_1_lt_/span_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t \n\t\t\t_lt_/td_gt_\n\t\t_lt_/tr_gt__lt_tr_gt__lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span_gt_21.0 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_#999999_sm__qt__gt_0.59 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span_gt_36.0 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_#999999_sm__qt__gt_1.01 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\tt.RotationYawPitchRollToRef_lt_span style_eq__qt_color_dd_#808080_sm__qt__gt_babylon.js_dd_2_lt_/span_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t \n\t\t\t_lt_/td_gt_\n\t\t_lt_/tr_gt__lt_tr_gt__lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span_gt_14.0 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_#999999_sm__qt__gt_0.39 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span_gt_14.0 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_#999999_sm__qt__gt_0.39 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\tt.ScalingToRef_lt_span style_eq__qt_color_dd_#808080_sm__qt__gt_babylon.js_dd_2_lt_/span_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t \n\t\t\t_lt_/td_gt_\n\t\t_lt_/tr_gt__lt_tr_gt__lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span_gt_12.6 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_#999999_sm__qt__gt_0.35 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span_gt_12.6 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_#999999_sm__qt__gt_0.35 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\tget_lt_span style_eq__qt_color_dd_#808080_sm__qt__gt_babylon.js_dd_6_lt_/span_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t \n\t\t\t_lt_/td_gt_\n\t\t_lt_/tr_gt__lt_tr_gt__lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span_gt_10.7 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_#999999_sm__qt__gt_0.30 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span_gt_10.7 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_#999999_sm__qt__gt_0.30 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\tt.TranslationToRef_lt_span style_eq__qt_color_dd_#808080_sm__qt__gt_babylon.js_dd_2_lt_/span_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t \n\t\t\t_lt_/td_gt_\n\t\t_lt_/tr_gt__lt_tr_gt__lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span_gt_10.3 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_#999999_sm__qt__gt_0.29 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span_gt_10.3 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_#999999_sm__qt__gt_0.29 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\tt.getScene_lt_span style_eq__qt_color_dd_#808080_sm__qt__gt_babylon.js_dd_6_lt_/span_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t \n\t\t\t_lt_/td_gt_\n\t\t_lt_/tr_gt__lt_tr_gt__lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span_gt_4.8 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_#999999_sm__qt__gt_0.13 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span_gt_4.8 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_#999999_sm__qt__gt_0.13 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\tget_lt_span style_eq__qt_color_dd_#808080_sm__qt__gt_babylon.js_dd_7_lt_/span_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t \n\t\t\t_lt_/td_gt_\n\t\t_lt_/tr_gt__lt_tr_gt__lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span_gt_4.1 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_#999999_sm__qt__gt_0.12 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span_gt_4.1 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_#999999_sm__qt__gt_0.12 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\tget_lt_span style_eq__qt_color_dd_#808080_sm__qt__gt_babylon.js_dd_7_lt_/span_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t \n\t\t\t_lt_/td_gt_\n\t\t_lt_/tr_gt__lt_tr_gt__lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span_gt_3.4 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_#999999_sm__qt__gt_0.10 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span_gt_3.4 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_#999999_sm__qt__gt_0.10 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\tget_lt_span style_eq__qt_color_dd_#808080_sm__qt__gt_babylon.js_dd_7_lt_/span_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t \n\t\t\t_lt_/td_gt_\n\t\t_lt_/tr_gt__lt_tr_gt__lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span_gt_1.0 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_#999999_sm__qt__gt_0.03 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span_gt_1.0 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_#999999_sm__qt__gt_0.03 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\tr.getRenderId_lt_span style_eq__qt_color_dd_#808080_sm__qt__gt_babylon.js_dd_9_lt_/span_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t \n\t\t\t_lt_/td_gt_\n\t\t_lt_/tr_gt__lt_tr_gt__lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span_gt_0.9 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_#999999_sm__qt__gt_0.02 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span_gt_0.9 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_#999999_sm__qt__gt_0.02 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\tget_lt_span style_eq__qt_color_dd_#808080_sm__qt__gt_babylon.js_dd_6_lt_/span_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t \n\t\t\t_lt_/td_gt_\n\t\t_lt_/tr_gt__lt_tr_gt__lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span_gt_0 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_#999999_sm__qt__gt_0 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t_lt_div_gt_\n\t\t\t\t\t_lt_span_gt_349.8 ms_lt_/span_gt__lt_span style_eq__qt_color_dd_#999999_sm__qt__gt_9.78 %_lt_/span_gt_\n\t\t\t\t_lt_/div_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\ti._updateBoundingInfo_lt_span style_eq__qt_color_dd_#808080_sm__qt__gt_babylon.js_dd_0_lt_/span_gt_\n\t\t\t_lt_/td_gt_\n\t\t\t_lt_td_gt_\n\t\t\t\t \n\t\t\t_lt_/td_gt_\n\t\t_lt_/tr_gt__lt_tr_gt__lt_td_gt_\n\t\t\t\t \n\t\t\t_lt_/td_gt_\n\t\t_lt_/tr_gt__lt_/tbody_gt__lt_/table_gt__lt_p_gt_\n\tMost of the time in _lt_em_gt_computeWorldMatrix()_lt_/em_gt_ is spent then in _lt_em_gt_multiplyToRef()_lt_/em_gt_ (10.35%) and in_lt_em_gt_ updateBoundingInfo()_lt_/em_gt_ (9.78%)\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_em_gt_Matrix.multiplyToRef()_lt_/em_gt_ calls then _lt_em_gt_Matrix.multiplyToArray()_lt_/em_gt_ what consumes 8% of the total time \n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_a href_eq__qt_https_dd_//github.com/BabylonJS/Babylon.js/blob/master/src/Math/babylon.math.ts#L3376_qt_ rel_eq__qt_external nofollow_qt__gt_https_dd_//github.com/BabylonJS/Babylon.js/blob/master/src/Math/babylon.math.ts#L3376_lt_/a_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\tIt_t_s 32 float allocations and 16 linear operations per call ... so for you 32 x 800 float allocations _eq_ 25600  each time multiplyToRef() is called !\n_lt_/p_gt_\n\n_lt_p_gt_\n\tI guess we could get rid of the float allocations since we can_t_t skip the linear operations. I used to make this kind of little opmitizations for _lt_em_gt_ComputeNormals()_lt_/em_gt_ or the SPS. Dozens of float allocations per frame don_t_t really matter_co_ but dozens of thousands really start to matter.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tFor the bInfo update_co_ most of the time (9.22 %) is spent in the _lt_em_gt_bBox._update()_lt_/em_gt_  in no particular sub call _dd_ \n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_a href_eq__qt_https_dd_//github.com/BabylonJS/Babylon.js/blob/master/src/Culling/babylon.boundingBox.ts#L66_qt_ rel_eq__qt_external nofollow_qt__gt_https_dd_//github.com/BabylonJS/Babylon.js/blob/master/src/Culling/babylon.boundingBox.ts#L66_lt_/a_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\tWell_co_ it_t_s just that we do 800 x 8 box vertex computations and checks to localize them in the World.\n_lt_/p_gt_\n\n_lt_p_gt_\n\t \n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"JCPalmer","Date":"2017-07-22T18:55:00Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tWorth mentioning_co_ right after FreezeWorldMatrix() was added_co_ I changed it so that it calls computeWorldMatrix(true) inside.  This can be valuable for meshes that only rarely move_co_ cutting out one step.  Not sure this will apply to your situation_co_ but if not all the meshes move every frame_co_ you could just re-freeze it every frame a given mesh moves.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tSome of the reason computeWorldMatrix() is so heavy_co_ is the parent checking_co_ sync checking.  It might be worth modifying it to check if rotation or scale changed_co_ if not only _lt_a href_eq__qt_https_dd_//github.com/BabylonJS/Babylon.js/blob/master/src/Math/babylon.math.ts#L3300_qt_ rel_eq__qt_external nofollow_qt__gt_setting the translation_lt_/a_gt_ only requires copying position.[x y z] to matrix.[12 13 14].  Then again that_t_s more checking.\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"jerome","Date":"2017-07-22T19:30:20Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tIf no billboard mode and no parent are used_co_ _lt_em_gt_multiplyToRef()_lt_/em_gt_ (matrix multiplication) is still called several times in each call to _lt_em_gt_computeWorldMatrix()_lt_/em_gt_ _dd_\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_a href_eq__qt_https_dd_//github.com/BabylonJS/Babylon.js/blob/master/src/Mesh/babylon.abstractMesh.ts#L1157_qt_ rel_eq__qt_external nofollow_qt__gt_https_dd_//github.com/BabylonJS/Babylon.js/blob/master/src/Mesh/babylon.abstractMesh.ts#L1157_lt_/a_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_a href_eq__qt_https_dd_//github.com/BabylonJS/Babylon.js/blob/master/src/Mesh/babylon.abstractMesh.ts#L1158_qt_ rel_eq__qt_external nofollow_qt__gt_https_dd_//github.com/BabylonJS/Babylon.js/blob/master/src/Mesh/babylon.abstractMesh.ts#L1158_lt_/a_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_a href_eq__qt_https_dd_//github.com/BabylonJS/Babylon.js/blob/master/src/Mesh/babylon.abstractMesh.ts#L1158_qt_ rel_eq__qt_external nofollow_qt__gt_https_dd_//github.com/BabylonJS/Babylon.js/blob/master/src/Mesh/babylon.abstractMesh.ts#L1158_lt_/a_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_a href_eq__qt_https_dd_//github.com/BabylonJS/Babylon.js/blob/master/src/Mesh/babylon.abstractMesh.ts#L1158_qt_ rel_eq__qt_external nofollow_qt__gt_https_dd_//github.com/BabylonJS/Babylon.js/blob/master/src/Mesh/babylon.abstractMesh.ts#L1158_lt_/a_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\tSo_co_ if I_t_m not wrong 4 times per call to _lt_em_gt_computeWorldMatrix() _lt_/em_gt_at least. This means_co_ in _lt_a contenteditable_eq__qt_false_qt_ data-ipshover_eq__qt__qt_ data-ipshover-target_eq__qt_http_dd_//www.html5gamedevs.com/profile/12925-fenomas/?do_eq_hovercard_qt_ data-mentionid_eq__qt_12925_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/profile/12925-fenomas/_qt_ rel_eq__qt__qt__gt_@fenomas_lt_/a_gt_ case 25600 x 4 _eq_ 102 400 float allocations per frame.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tThis could be avoided. I_t_ll talk about this to _lt_a contenteditable_eq__qt_false_qt_ data-ipshover_eq__qt__qt_ data-ipshover-target_eq__qt_http_dd_//www.html5gamedevs.com/profile/4442-deltakosh/?do_eq_hovercard_qt_ data-mentionid_eq__qt_4442_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/profile/4442-deltakosh/_qt_ rel_eq__qt__qt__gt_@Deltakosh_lt_/a_gt_\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"fenomas","Date":"2017-07-23T06:00:48Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_blockquote class_eq__qt_ipsQuote_qt_ data-ipsquote_eq__qt__qt_ data-ipsquote-contentapp_eq__qt_forums_qt_ data-ipsquote-contentclass_eq__qt_forums_Topic_qt_ data-ipsquote-contentcommentid_eq__qt_182706_qt_ data-ipsquote-contentid_eq__qt_31786_qt_ data-ipsquote-contenttype_eq__qt_forums_qt_ data-ipsquote-timestamp_eq__qt_1500708323_qt_ data-ipsquote-userid_eq__qt_5453_qt_ data-ipsquote-username_eq__qt_jerome_qt__gt_\n\t_lt_div class_eq__qt_ipsQuote_citation_qt__gt_\n\t\t21 hours ago_co_ jerome said_dd_\n\t_lt_/div_gt_\n\n\t_lt_div class_eq__qt_ipsQuote_contents_qt__gt_\n\t\t_lt_p_gt_\n\t\t\tofile results as a tree (topdown)_co_ the percentage of the time used by computeWorldMatrix() while 7200 ms is _qt_only_qt_  37% of the total time for me ... what still seems a high ratio imho\n\t\t_lt_/p_gt_\n\t_lt_/div_gt_\n_lt_/blockquote_gt_\n\n_lt_p_gt_\n\tSo_co_ the absolute numbers will change from profile to profile_co_ depending on your machine_t_s CPU and so forth. So what I usually do is_co_ look at the total time spent executing scripts compared to the time spent at some point in the _qt_call tree_qt_ graph. \n_lt_/p_gt_\n\n_lt_p_gt_\n\tFor example_co_ if the root of the tree (_qt_Animation frame fired_qt_) has a total time of 50%_co_ and further down in the tree _qt_computeWorldMatrix_qt_ has a total time of 25%_co_ one can say that computeWorldMatrix is accounting for about half the script execution time. On a slower machine it might be 80% and 40%_co_ so the absolute numbers can be misleading but the ratios sort of tell you what_t_s going on.\n_lt_/p_gt_\n\n_lt_p_gt_\n\t \n_lt_/p_gt_\n\n_lt_blockquote class_eq__qt_ipsQuote_qt_ data-ipsquote_eq__qt__qt_ data-ipsquote-contentapp_eq__qt_forums_qt_ data-ipsquote-contentclass_eq__qt_forums_Topic_qt_ data-ipsquote-contentcommentid_eq__qt_182706_qt_ data-ipsquote-contentid_eq__qt_31786_qt_ data-ipsquote-contenttype_eq__qt_forums_qt_ data-ipsquote-timestamp_eq__qt_1500708323_qt_ data-ipsquote-userid_eq__qt_5453_qt_ data-ipsquote-username_eq__qt_jerome_qt__gt_\n\t_lt_div class_eq__qt_ipsQuote_citation_qt__gt_\n\t\t21 hours ago_co_ jerome said_dd_\n\t_lt_/div_gt_\n\n\t_lt_div class_eq__qt_ipsQuote_contents_qt__gt_\n\t\t_lt_p_gt_\n\t\t\tI guess we could get rid of the float allocations since we can_t_t skip the linear operations. I used to make this kind of little opmitizations for _lt_em_gt_ComputeNormals()_lt_/em_gt_ or the SPS. Dozens of float allocations per frame don_t_t really matter_co_ but dozens of thousands really start to matter.\n\t\t_lt_/p_gt_\n\t_lt_/div_gt_\n_lt_/blockquote_gt_\n\n_lt_p_gt_\n\tWhen you start to talk about stuff like this_co_ you really have to know what_t_s going on inside V8 to make predictions about what will improve performance. For code like _lt_a href_eq__qt_https_dd_//github.com/BabylonJS/Babylon.js/blob/master/src/Math/babylon.math.ts#L3376_qt_ rel_eq__qt_external nofollow_qt__gt_here_lt_/a_gt__co_ just because there are a lot of _qt__lt_span style_eq__qt_color_dd_#d73a49_sm__qt__gt_var_lt_/span_gt__lt_span style_eq__qt_color_dd_#24292e_sm__qt__gt_ tm5 _lt_/span_gt__lt_span style_eq__qt_color_dd_#d73a49_sm__qt__gt__eq__lt_/span_gt__lt_span style_eq__qt_color_dd_#24292e_sm__qt__gt_ _lt_/span_gt__lt_span style_eq__qt_color_dd_#005cc5_sm__qt__gt_this_lt_/span_gt__lt_span style_eq__qt_color_dd_#24292e_sm__qt__gt_._lt_/span_gt__lt_span style_eq__qt_color_dd_#24292e_sm__qt__gt_m_lt_/span_gt__lt_span style_eq__qt_color_dd_#24292e_sm__qt__gt_[_lt_/span_gt__lt_span style_eq__qt_color_dd_#005cc5_sm__qt__gt_5_lt_/span_gt__lt_span style_eq__qt_color_dd_#24292e_sm__qt__gt_]_sm__qt_ statements doesn_t_t necessarily mean that the JS engine is allocating new floats onto the stack - the optimizing compiler does a lot of magic and it_t_s hard to predict how it all works._lt_/span_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_span style_eq__qt_color_dd_#24292e_sm__qt__gt_The best way I_t_ve found to test performance improvements for low-level stuff like this is to make two versions of the function that I want to compare_co_ and then route the code so that it alternates between each version. They you can just profile_co_ and see which function took more execution time._lt_/span_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_span style_eq__qt_color_dd_#24292e_sm__qt__gt_For example_co_ here_t_s what this would look like for testing _lt_strong_gt_multiplyToArray_dd__lt_/strong_gt__lt_/span_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_a href_eq__qt_http_dd_//www.babylonjs-playground.com/#E2HVNG%231_qt_ rel_eq__qt_external nofollow_qt__gt_http_dd_//www.babylonjs-playground.com/#E2HVNG#1_lt_/a_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\tDown at the bottom you can see that I define two alternate versions_co_ one just like the original and one that doesn_t_t declare temp vars. If you profile that you should find that the original version is somewhat faster than the alternate. (Not to say that the function can_t_t be improved - I think I can speed it up moderately_co_ but the other stuff you_t_re looking at sounds more likely to be valuable)\n_lt_/p_gt_\n\n_lt_p_gt_\n\t \n_lt_/p_gt_\n\n_lt_blockquote class_eq__qt_ipsQuote_qt_ data-ipsquote_eq__qt__qt_ data-ipsquote-contentapp_eq__qt_forums_qt_ data-ipsquote-contentclass_eq__qt_forums_Topic_qt_ data-ipsquote-contentcommentid_eq__qt_182742_qt_ data-ipsquote-contentid_eq__qt_31786_qt_ data-ipsquote-contenttype_eq__qt_forums_qt_ data-ipsquote-timestamp_eq__qt_1500751820_qt_ data-ipsquote-userid_eq__qt_5453_qt_ data-ipsquote-username_eq__qt_jerome_qt__gt_\n\t_lt_div class_eq__qt_ipsQuote_citation_qt__gt_\n\t\t10 hours ago_co_ jerome said_dd_\n\t_lt_/div_gt_\n\n\t_lt_div class_eq__qt_ipsQuote_contents_qt__gt_\n\t\t_lt_p_gt_\n\t\t\tThis could be avoided. I_t_ll talk about this to _lt_a contenteditable_eq__qt_false_qt_ data-ipshover_eq__qt__qt_ data-ipshover-target_eq__qt_http_dd_//www.html5gamedevs.com/profile/4442-deltakosh/?do_eq_hovercard_qt_ data-mentionid_eq__qt_4442_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/profile/4442-deltakosh/_qt_ rel_eq__qt__qt__gt_@Deltakosh_lt_/a_gt_\n\t\t_lt_/p_gt_\n\t_lt_/div_gt_\n_lt_/blockquote_gt_\n\n_lt_p_gt_\n\tThis part of the code I don_t_t understand at all_co_ but if calls can be skipped that_t_d be cool. Thanks for looking at it!\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"jerome","Date":"2017-07-23T07:44:40Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tAs you said_co_ the V8 engine does a lot of magic under the hood and we can_t_t easily predict where the gain would be.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tNevertheless_co_ when doing _qt_var tm5 _eq_ someFloat_qt__co_ the engine has to create a float var anyway (floats are stored in the heap in JS_co_ not in the stack)_co_ because _lt_em_gt_tm5_lt_/em_gt_ can be set then with any other value.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tI_t_m not that expert_co_ but I spent hours to compare the behavior of _lt_em_gt_ComputeNormals()_lt_/em_gt_ with and without the temp variables_co_ what were here just for readability reasons_co_ at the time I optimized it (up to x5 faster). The same (spent days there) with the behavior of all the internal computations (positions_co_ normals_co_ rotations_co_ quatertions_co_ uvs_co_ colors) of the SPS to try to make it almost as fast as the legagy 2D particle system.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tUsing a 10 yo laptop to make those comparisons_co_ I can say there is a substantial gain when we deal with more than 8-10K calls per frame. This is an empirical value obviously but I noticed there was_co_ on every machine_co_ a limit where the CPU has so many things to do while 16 ms that skipping 10K scalar variable allocations (not objects_co_ I don_t_t even speak about the GC here) per frame could make a real difference.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tYour case seems to reach this limit because_co_ just counting them_co_ it_t_s about 100K floats stacked and removed from the heap per frame. Even if it_t_s only a part of 8% of the time on my machine_co_ I guess it_t_s worth a try to avoid this as this can be done. DK is OK for this. Unfortunately I won_t_t do it before end of august or early september (no code for now).\n_lt_/p_gt_\n\n_lt_p_gt_\n\t \n_lt_/p_gt_\n\n_lt_p_gt_\n\tNot sure it_t_s possible for your own case_co_ but did you try the SPS approach ? store your 800 meshes in one SPS (if possible)_co_ then move them and compare the perfs ...\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"fenomas","Date":"2017-07-23T16:02:39Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_blockquote class_eq__qt_ipsQuote_qt_ data-ipsquote_eq__qt__qt_ data-ipsquote-contentapp_eq__qt_forums_qt_ data-ipsquote-contentclass_eq__qt_forums_Topic_qt_ data-ipsquote-contentcommentid_eq__qt_182769_qt_ data-ipsquote-contentid_eq__qt_31786_qt_ data-ipsquote-contenttype_eq__qt_forums_qt_ data-ipsquote-timestamp_eq__qt_1500795880_qt_ data-ipsquote-userid_eq__qt_5453_qt_ data-ipsquote-username_eq__qt_jerome_qt__gt_\n\t_lt_div class_eq__qt_ipsQuote_citation_qt__gt_\n\t\t7 hours ago_co_ jerome said_dd_\n\t_lt_/div_gt_\n\n\t_lt_div class_eq__qt_ipsQuote_contents_qt__gt_\n\t\t_lt_p_gt_\n\t\t\tbecause _lt_em_gt_tm5_lt_/em_gt_ can be set then with any other value\n\t\t_lt_/p_gt_\n\t_lt_/div_gt_\n_lt_/blockquote_gt_\n\n_lt_p_gt_\n\tJust some trivia_co_ but V8 follows _qt__lt_a href_eq__qt_https_dd_//en.wikipedia.org/wiki/Static_single_assignment_form_qt_ rel_eq__qt_external nofollow_qt__gt_single static assignment_lt_/a_gt__qt_ form_co_ so internally local variables never change values. That is_co_ if you reassign a new value to _lt_em_gt_tm5_lt_/em_gt__co_ the optimizing compiler will compile it as if you had created a new variable.\n_lt_/p_gt_\n\n_lt_p_gt_\n\t \n_lt_/p_gt_\n\n_lt_blockquote class_eq__qt_ipsQuote_qt_ data-ipsquote_eq__qt__qt_ data-ipsquote-contentapp_eq__qt_forums_qt_ data-ipsquote-contentclass_eq__qt_forums_Topic_qt_ data-ipsquote-contentcommentid_eq__qt_182769_qt_ data-ipsquote-contentid_eq__qt_31786_qt_ data-ipsquote-contenttype_eq__qt_forums_qt_ data-ipsquote-timestamp_eq__qt_1500795880_qt_ data-ipsquote-userid_eq__qt_5453_qt_ data-ipsquote-username_eq__qt_jerome_qt__gt_\n\t_lt_div class_eq__qt_ipsQuote_citation_qt__gt_\n\t\t7 hours ago_co_ jerome said_dd_\n\t_lt_/div_gt_\n\n\t_lt_div class_eq__qt_ipsQuote_contents_qt__gt_\n\t\t_lt_p_gt_\n\t\t\tthe engine has to create a float var anyway (floats are stored in the heap in JS_co_ not in the stack)\n\t\t_lt_/p_gt_\n\t_lt_/div_gt_\n_lt_/blockquote_gt_\n\n_lt_p_gt_\n\tAFAIK v8 is smart enough to create temp variables in registers if it knows they won_t_t be needed for long. For the function we_t_re talking about I imagine it may not have enough registers to do this for all the floats_co_ so some may get created on the heap as well_co_ but this gets into the kind of areas where v8 may not work the same way on all platforms_co_ or it may allocate registers differently next month than it does today. I don_t_t think it_t_s possible to say anything with certainty without looking at decompiled IR.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tThat said_co_ for what it_t_s worth I played a little with optimizing multplyToArray_co_ and got a moderate speedup just by moving code around_dd_\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_a href_eq__qt_http_dd_//www.babylonjs-playground.com/#E2HVNG%232_qt_ rel_eq__qt_external nofollow_qt__gt_http_dd_//www.babylonjs-playground.com/#E2HVNG#2_lt_/a_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\tAll the alternate version does is move some var assignments down to occur right before they_t_re needed. My guess is that this lets the compiler make better guesses about how to reuse registers. (E.g. putting tm0-3 into registers_co_ and then later putting tm4-7 into those same registers because tm0-3 are no longer needed.)\n_lt_/p_gt_\n\n_lt_p_gt_\n\t \n_lt_/p_gt_\n\n_lt_blockquote class_eq__qt_ipsQuote_qt_ data-ipsquote_eq__qt__qt_ data-ipsquote-contentapp_eq__qt_forums_qt_ data-ipsquote-contentclass_eq__qt_forums_Topic_qt_ data-ipsquote-contentcommentid_eq__qt_182769_qt_ data-ipsquote-contentid_eq__qt_31786_qt_ data-ipsquote-contenttype_eq__qt_forums_qt_ data-ipsquote-timestamp_eq__qt_1500795880_qt_ data-ipsquote-userid_eq__qt_5453_qt_ data-ipsquote-username_eq__qt_jerome_qt__gt_\n\t_lt_div class_eq__qt_ipsQuote_citation_qt__gt_\n\t\t7 hours ago_co_ jerome said_dd_\n\t_lt_/div_gt_\n\n\t_lt_div class_eq__qt_ipsQuote_contents_qt__gt_\n\t\t_lt_p_gt_\n\t\t\tNot sure it_t_s possible for your own case_co_ but did you try the SPS approach ?\n\t\t_lt_/p_gt_\n\t_lt_/div_gt_\n_lt_/blockquote_gt_\n\n_lt_p_gt_\n\tI_t_ve experimented with it_co_ but it_t_s not ideal_co_ since my scene doesn_t_t _lt_em_gt_always_lt_/em_gt_ have 800 meshes_co_ that_t_s just a rough upper limit. So I_t_d probably need to create and destroy SPSes according to demand_co_ which would be hairy.\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"adam","Date":"2017-07-31T08:43:20Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tUnfortunately that multiplyToArray optimization would create a bug when a user does this\n_lt_/p_gt_\n\n_lt_p_gt_\n\tmat1.multiplyToRef(mat2_co_ mat1)\n_lt_/p_gt_\n\n_lt_p_gt_\n\tedit_dd_\n_lt_/p_gt_\n\n_lt_p_gt_\n\ti just looked more closely at the function (on my phone).  I might be wrong.  You should keep this case in mind though.\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"Deltakosh","Date":"2017-07-31T17:58:08Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t_lt_p_gt_\n\tYes it was my thinking as well\n_lt_/p_gt_\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"}]