[{"Owner":"JCPalmer","Date":"2017-12-01T18:04:26Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tThis topic is a follow up to one of the _qt_what_t_s next?_qt_ comments I _lt_a href_eq__qt_http_dd_//www.html5gamedevs.com/topic/33982-whats-next/?tab_eq_comments#comment-195807_qt_ rel_eq__qt__qt__gt_made_lt_/a_gt_.  I have added facility into an addon for Blender_co_ which allows post import operations on MakeHuman meshes / skeletons.  The button highlighted_co_ converts the 160 some odd bone_co_ default skeleton to one made for Kinect2.\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_img alt_eq__qt_5a217efb7a41a_communitytab.JPG.36910975e1a8787ae5b8daa93d27a568.JPG_qt_ class_eq__qt_ipsImage ipsImage_thumbnailed_qt_ data-fileid_eq__qt_16069_qt_ src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/monthly_2017_12/5a217efb7a41a_communitytab.JPG.36910975e1a8787ae5b8daa93d27a568.JPG_qt_ /_gt__lt_a class_eq__qt_ipsAttachLink ipsAttachLink_image_qt_ data-fileid_eq__qt_16070_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/uploads/monthly_2017_12/5a217f0c1ebd6_kinetics2rig.JPG.7dd0eea849edadee3743fac7f154d882.JPG_qt_ rel_eq__qt__qt__gt__lt_img alt_eq__qt_5a217f0c28be9_kinetics2rig.thumb.JPG.01daf68c55b9b245ca6d561bf71b7986.JPG_qt_ class_eq__qt_ipsImage ipsImage_thumbnailed_qt_ data-fileid_eq__qt_16070_qt_ src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/monthly_2017_12/5a217f0c28be9_kinetics2rig.thumb.JPG.01daf68c55b9b245ca6d561bf71b7986.JPG_qt_ /_gt__lt_/a_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\tThe bones are named for the bone tail which lines up to the joints the sensor_t_s output.  There was an _lt_a href_eq__qt_http_dd_//www.html5gamedevs.com/topic/19043-avatar-animation-via-kinect-v2/_qt_ rel_eq__qt__qt__gt_old topic_lt_/a_gt_ about this_co_ but_dd_\n_lt_/p_gt_\n\n_lt_ul_gt__lt_li_gt_\n\t\tThe people are gone.\n\t_lt_/li_gt_\n\t_lt_li_gt_\n\t\tThey shared nothing but pictures.\n\t_lt_/li_gt_\n\t_lt_li_gt_\n\t\tThis includes their skeleton_co_ which could have been the reason for all their problems.\n\t_lt_/li_gt_\n_lt_/ul_gt__lt_p_gt_\n\tHere is a _lt_a href_eq__qt_https_dd_//github.com/Palmer-JC/Palmer-JC.github.io/blob/master/kinects2.blend_qt_ rel_eq__qt_external nofollow_qt__gt_.blend_lt_/a_gt_ of my converted skeleton.  Any comments would be appreciated_co_ _lt_a contenteditable_eq__qt_false_qt_ data-ipshover_eq__qt__qt_ data-ipshover-target_eq__qt_http_dd_//www.html5gamedevs.com/profile/7026-gryff/?do_eq_hovercard_qt_ data-mentionid_eq__qt_7026_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/profile/7026-gryff/_qt_ rel_eq__qt__qt__gt_@gryff_lt_/a_gt__co_ _lt_a contenteditable_eq__qt_false_qt_ data-ipshover_eq__qt__qt_ data-ipshover-target_eq__qt_http_dd_//www.html5gamedevs.com/profile/11286-dbawel/?do_eq_hovercard_qt_ data-mentionid_eq__qt_11286_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/profile/11286-dbawel/_qt_ rel_eq__qt__qt__gt_@dbawel_lt_/a_gt_ maybe?  The skeleton units are in decimeters_co_ which are easy to convert the sensor_t_s meters to_co_ but any solution should probably have a units multiplier.  The .blend is already in weight paint mode_co_ seen below.  Just RIGHT click any bone to see its weighting on vertices.\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_a class_eq__qt_ipsAttachLink ipsAttachLink_image_qt_ data-fileid_eq__qt_16071_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/uploads/monthly_2017_12/5a21829eb895f_kinetics2rigpainted.JPG.c16ce9ad8cb9d3c860cabc4b9c1484b4.JPG_qt_ rel_eq__qt__qt__gt__lt_img alt_eq__qt_5a21829ec5497_kinetics2rigpainted.thumb.JPG.ad12b85ef919a7069e0990d04b365617.JPG_qt_ class_eq__qt_ipsImage ipsImage_thumbnailed_qt_ data-fileid_eq__qt_16071_qt_ src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/monthly_2017_12/5a21829ec5497_kinetics2rigpainted.thumb.JPG.ad12b85ef919a7069e0990d04b365617.JPG_qt_ /_gt__lt_/a_gt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\tFor the rest of this topic_co_ I am just sounding out how I think this might be implemented in 3.2.  DB_co_ for your electronics company work_co_ I think you are going to have time requirements which are too tight for waiting for 3.2.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tFirst_co_ I wish to use this for pose capture_co_ but making changes to the Skeleton class (or QI Skeleton sub-class) to do live animating may actually help debug things &amp_sm_ therefore be a twofer.  To this skeleton class_co_ if the bones array cannot be changed to a _lt_strong_gt_{ [bone_dd_ string] _dd_ BABYLON.Bone }_lt_/strong_gt_ dictionary for compatibility reasons_co_ I think there needs to be some additional data elements &amp_sm_ a method to switch on Kinetics_co_ because calling getBoneIndexByName() 25 times every update is probably slower.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tNext thing is_co_ yes bones are basically a local matrix to the bone parent_co_ &amp_sm_ kinetics returns data in it_t_s world space_co_  BUT that is no reason to go all the trouble of converting sensor output to local space (unless doing mocap - more later)_co_ WHEN skeleton.prepare() is just going to have to convert it back.  Performance could suck.  Having an alternate  _computeTransformMatrics() seems like the level to branch off to convert from kinect space to world space.  Here is a non-running mock up of all these changes_dd_\n_lt_/p_gt_\n\n_lt_pre_gt_\n_lt_code_gt_public onAfterComputeObservable _eq_ new Observable&lt_sm_Skeleton&gt_sm_()_sm_\nprotected _kinectsDictionary _dd_ { [bone_dd_ string] _dd_ BABYLON.Bone }_sm_\nprotected _useKinetics _dd_ boolean_sm_\nprotected _kineticsBody _dd_ any_sm_\nprotected _kinecticsBodyIdx _dd_ number_sm_\nprotected _kinecticsUnits _dd_ number_sm_\nprotected _kineticsFloorClipPlane _dd_ BABYLON.Quaternion_sm_\n\npublic switchToKinetics(val _dd_ boolean_co_ units _eq_ 1_co_ bodyIdx _eq_ 0) _dd_ void {\n    this._useKinetics _eq_ val_sm_\n    if (val) {\n        for (var i _eq_ 0_co_ len _eq_ this.bones.length_sm_ i &lt_sm_ len_sm_ i++) {\n            this._kinectsDictionary[this.bones[i].name] _eq_ this.bones[i]_sm_\n        }\n        this._kinecticsUnits _eq_ units_sm_\n        this._kinecticsBodyIdx _eq_ bodyIdx_sm_\n        \n    } else this._kinectsDictionary _eq_ null_sm_\n}\n\npublic incomingKineticsDataCallback(eventData _dd_ string) _dd_ void {\n    var parsed _eq_ JSON.stringify(eventData)_sm_\n    this._kineticsBody _eq_ parsed.bodies[this._kinecticsBodyIdx]_sm_\n    \n    // account for right handed to left handed for this here\n    this._kineticsFloorClipPlane _eq_ new BABYLON.Quaternion(\n        parsed.floorClipPlane.x_co_\n        parsed.floorClipPlane.z_co_\n        parsed.floorClipPlane.y_co_\n        parsed.floorClipPlane.w\n    )_sm_\n    this._markAsDirty()_sm_\n}\n\n/**\n * @override\n */\npublic _computeTransformMatrices(targetMatrix_dd_ Float32Array_co_ initialSkinMatrix_dd_ BABYLON.Matrix) _dd_ void {\n    if (this._useKinetics) {\n        this._kineticsTransformMatrices(targetMatrix_co_ initialSkinMatrix)_sm_\n    }else{\n        super._computeTransformMatrices(targetMatrix_co_ initialSkinMatrix)_sm_\n    }\n    this.onAfterComputeObservable.notifyObservers(this)_sm_\n}\n\nprotected _kineticsTransformMatrices(targetMatrix_dd_ Float32Array_co_ initialSkinMatrix_dd_ BABYLON.Matrix) _dd_ void {\n    // ...\n}\n_lt_/code_gt__lt_/pre_gt_\n\n_lt_p_gt_\n\tFor using this for capture_co_ maybe a method in the bone class say_co_ worldToLocalMatrix()_co_ which could be called by code monitoring the onAfterComputeObservable.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tThis is my current straw man.  I do not even have the hardware_co_ right now.  Thoughts?\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"dbawel","Date":"2017-12-02T03:04:38Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\t_lt_a contenteditable_eq__qt_false_qt_ data-ipshover_eq__qt__qt_ data-ipshover-target_eq__qt_http_dd_//www.html5gamedevs.com/profile/8492-jcpalmer/?do_eq_hovercard_qt_ data-mentionid_eq__qt_8492_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/profile/8492-jcpalmer/_qt_ rel_eq__qt__qt__gt_@JCPalmer_lt_/a_gt_-\n_lt_/p_gt_\n\n_lt_p_gt_\n\tDo you have the scene available for upload into Blender? Either FBX_co_ STL_co_ OBJ_co_ etc? FBX is preferable for me. Although I_t_d love it if you have time to define your general process in connecting the Kinect V2 to Blender - if indeed you are doing this. I still use the Brekel python plugin from my good friend Oshri_t_s lab in Switzerland. Man that takes me way back when Oshri and I were in Thailand at a Bhuddist temple capturing Motaro for the Mortal Kombat films.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tDB\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"JCPalmer","Date":"2017-12-02T18:49:39Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\t_lt_a contenteditable_eq__qt_false_qt_ data-ipshover_eq__qt__qt_ data-ipshover-target_eq__qt_http_dd_//www.html5gamedevs.com/profile/11286-dbawel/?do_eq_hovercard_qt_ data-mentionid_eq__qt_11286_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/profile/11286-dbawel/_qt_ rel_eq__qt__qt__gt_@dbawel_lt_/a_gt__co_ do you have _lt_a href_eq__qt_http_dd_//brekel.com/brekel-pro-body-v2/_qt_ rel_eq__qt_external nofollow_qt__gt_this_lt_/a_gt__co_ or is there a Blender Python plugin somewhere?\n_lt_/p_gt_\n\n_lt_p_gt_\n\tThere is a link to a .blend file in first post.  Think Blender can export an fbx from it.   If you could see how well the converted skeleton performs_co_ that would be great!  I want to make the most perfect skeleton possible from MakeHuman for use with Kinect2.  If the skeleton is poor_co_ it sort of puts an upper limit on what can be done.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tI have no interest in making a Kinect2 interface for Blender myself_co_ but might use one since it would fit right into my workflow.  My final output will be using my pose interpolation_co_ which is improving (float free).  There is one important set of poses where IK might take a long time / or I might have to have to settle for low quality.  I am quite able to perform it myself using mocap then keyframe reduce.  Finding some mocap_co_ probably from a different skeleton_co_ from the web is both unlikely &amp_sm_ never going to translate right.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tI found _lt_a href_eq__qt_https_dd_//www.ebay.com/itm/New-Microsoft-Certified-Xbox-One-Kinect-2-0-Motion-Camera-Sensor/332410864902?hash_eq_item4d653b4506_dd_g_dd_Lp0AAOSw03VZ3-x0_dd_sc_dd_USPSPriority!14534!US!-1_qt_ rel_eq__qt_external nofollow_qt__gt_eBay _lt_/a_gt_has new Kinect2 sensors at $80_co_ so it definitely is within my budget.  Need to check around first_co_ though.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tI have other news on this proposal front_co_ but still need to check some things_co_ first.\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"dbawel","Date":"2017-12-04T03:15:02Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\t_lt_a contenteditable_eq__qt_false_qt_ data-ipshover_eq__qt__qt_ data-ipshover-target_eq__qt_http_dd_//www.html5gamedevs.com/profile/8492-jcpalmer/?do_eq_hovercard_qt_ data-mentionid_eq__qt_8492_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/profile/8492-jcpalmer/_qt_ rel_eq__qt__qt__gt_@JCPalmer_lt_/a_gt_-\n_lt_/p_gt_\n\n_lt_p_gt_\n\tI just looked and can_t_t believe that the Kinect V2 sells for as little as 50.00 US. I spent $200.00 a short while back_co_ so $50.00 is quite a good deal as the SDK can be downloaded for free. I should have waited_co_ although I couldn_t_t have worked on the device when it was released 2 years ago now.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tLet me know if you believe it isn_t_t too difficult to create a real-time open port plugin for the Kinect V2. I know I could certainly use such a tool.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tCheers_co_\n_lt_/p_gt_\n\n_lt_p_gt_\n\tDB\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"dbawel","Date":"2017-12-04T03:48:14Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\t_lt_a contenteditable_eq__qt_false_qt_ data-ipshover_eq__qt__qt_ data-ipshover-target_eq__qt_http_dd_//www.html5gamedevs.com/profile/8492-jcpalmer/?do_eq_hovercard_qt_ data-mentionid_eq__qt_8492_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/profile/8492-jcpalmer/_qt_ rel_eq__qt__qt__gt_@JCPalmer_lt_/a_gt_ -\n_lt_/p_gt_\n\n_lt_p_gt_\n\tYes_co_ I_t_ve been using the Brekel Pro Body V2 for a couple of years now_co_ as a my good friend Oshri owns the lab which this was developed out of. And the plugin works extremely well and has saved me countless hours of animation. However_co_ I_t_d like to take the next step and create this as an extension directly into babylon.js since the skeleton is a set and known bone configuration. So if you have any thoughts which might help create this as a BJS extension_co_ then i_t_d love to hear any ideas you might have. My new job requires me to delve into these areas_co_ and I_t_d much prefer to work on such tools with others thn entirely on my own.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tCheers_co_\n_lt_/p_gt_\n\n_lt_p_gt_\n\tDavid\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"JCPalmer","Date":"2017-12-04T19:19:25Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tOk_co_ I ordered my used Kinect V2 sensor_co_ $39.99_lt_sup_gt_95_lt_/sup_gt_ &amp_sm_ free shipping_co_ Saturday afternoon.  Today_co_ Monday its on my front porch before Noon.  First order of business is to prepare the room.  It really needs it with stacks of stuff_co_ but also I have a motherboard with 3.0 USB_co_ but the case it is in only has USB 2.0 ports on the top / front.  Need to plug-in from the back.  Might also need some sort of adapter_co_ since the end of the sensor cable looks female.  Some picture I saw looks shows a piece I never got.  Investigating_co_ there is an adapter needed to be bought when connecting using USB.  Probably is going to cost me more than the sensor_lt_img alt_eq__qt__dd_(_qt_ data-emoticon_eq__qt__qt_ height_eq__qt_20_qt_ src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/default_sad.png_qt_ srcset_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/sad@2x.png 2x_qt_ title_eq__qt__dd_(_qt_ width_eq__qt_20_qt_ /_gt_.\n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_img class_eq__qt_ipsImage ipsImage_thumbnailed_qt_ data-fileid_eq__qt_16111_qt_ src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/monthly_2017_12/dims.jpg.6403f24d1b89d3d674f9cc47a4b4dd71.jpg_qt_ alt_eq__qt_dims.jpg.6403f24d1b89d3d674f9cc47a4b4dd71.jpg_qt_ /_gt__lt_/p_gt_\n\n_lt_p_gt_\n\tI have been combing over the large collection of examples / github projects_co_ as well as the SDK.  There was a javascript interface supplied by the SDK 1.8_co_ but not included for 2.0.  Even that seemed slightly clunky.  If you go down to the comments of _lt_a href_eq__qt_https_dd_//msdn.microsoft.com/en-us/library/dn435664.aspx_qt_ rel_eq__qt_external nofollow_qt__gt_this_lt_/a_gt__co_ you have go to a sample program_co_ compile it_co_ and make changes to a config file to make the server part.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tThe websocket client / server approach_co_ which the _qt_thing_qt_ in 1.8 may or may not have been implemented in_co_ seems like the best way to do it.  It might even allow python clients_co_ depending on if a _qt_websocket_qt_ is really any different from a socket.  A free standing server program you might launch does not exist in all the things I have seen_co_ so far.  Having to install node.js_co_ even though I have_co_ restricts the usefulness to people who either cannot or do not want to have to install all this stuff.  Seems like too much can go wrong.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tOne of the _lt_a href_eq__qt_https_dd_//github.com/v-kiniv/kinect-js_qt_ rel_eq__qt_external nofollow_qt__gt_repos_lt_/a_gt__co_ seemed to have a reasonable JSON output_co_ but when I asked a question about a JS file referenced in the readme which was missing_co_ I was told the project was proprietary.  I saw one _lt_a href_eq__qt_https_dd_//peted.azurewebsites.net/kinect-4-windows-v2-in-the-browser/_qt_ rel_eq__qt_external nofollow_qt__gt_blog_lt_/a_gt__co_ that even mentioned babylonjs (about says he works for MS)_co_ that talked about using supersocket in a 22 line console app which wrapped everything in JSON.  There is a _lt_a href_eq__qt_https_dd_//github.com/peted70/kinectv2-webserver_qt_ rel_eq__qt_external nofollow_qt__gt_REPO _lt_/a_gt_based on this_co_ no license_co_ &amp_sm_ no actual binary that I can see.  I do not see everyone building their own .net app from source.  I do not know how to do it.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tThe saga continues..\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"dbawel","Date":"2017-12-05T02:42:06Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\t_lt_a contenteditable_eq__qt_false_qt_ data-ipshover_eq__qt__qt_ data-ipshover-target_eq__qt_http_dd_//www.html5gamedevs.com/profile/8492-jcpalmer/?do_eq_hovercard_qt_ data-mentionid_eq__qt_8492_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/profile/8492-jcpalmer/_qt_ rel_eq__qt__qt__gt_@JCPalmer_lt_/a_gt_-\n_lt_/p_gt_\n\n_lt_p_gt_\n\tIf the pic you posted above is your actual device_co_ then it appears you have everything you need to plug in a get up and running immediately. The only item I don_t_t see in the pic is the power supply. And I don_t_t entirely follow your issue with USB 3.0_co_ as you mentioned that your laptop is USB 3.0_co_ and you_t_re aware the Kinect V2 won_t_t work with USB 2.0. However_co_ with the adapter shown in the picture_co_ there is a cable to plug into your standard USB 3.0 port - unless you_t_re missing the unique cable adapter.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tBut if you are up for developing a plugin / extension to babylon.js from the Kinect V2_co_ then I know allot of developers which will be using such an extension daily. And I_t_m glad you can see the advantages in using the Kinect V2 over the Kinect V1 - as there is no comparison over the quality which the Kinect V2 provides - in all aspects especially the quality of the texture it captures which can easily be applied to the depth map_co_ as well as so many other uses for the image data.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tI_t_m ready to move forward if you are.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tAnd on a completely separate note_co_ I just purchased the Microsoft Surface 2 laptop_co_ and this is the very best laptop I_t_ve ever owned - by far. It_t_s a bit pricy at almost $3_co_000_co_ however as I need to use it for work_co_ it is entirely worth the price. It_t_s faster than any laptop or desktop I own_co_ and when removed from the bluetooth keyboard_co_ weighs 1.7 lbs. In addition_co_ I ordered a device I_t_d never heard of before which is the _qt_surface dial_qt_ and this device is awesome. I attach anywhere on the screen_co_ desktop_co_ or anywhere in proximity_co_ and can assign it as a controller for practically anything. Working in Photoshop is a real pleasure as I connect it to a variety of tools and it makes my workflow incredibly fast. For $99 (or less)_co_ I_t_ve found it to be invaluable for me personally. But take a look at the Surface 2_co_ as it is well worth the sticker price - and they were just released a couple of weeks ago. You_t_re looking at a TB of solid state hard drive and 8 GB of video RAM on the NVidea 1060 graphics card. Not to mention the best looking highest quality screen I_t_ve ever had on any device. And playing games is unparalleled even compared to my latest game consoles. Unbelievable.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tDB\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"JCPalmer","Date":"2017-12-05T21:11:01Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tThat was not my picture.  There is a _qt_Xbox Kinect Adapter for Xbox One S and Windows 10 PC_qt_. I ordered it.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tI cloned the _lt_a href_eq__qt_https_dd_//github.com/peted70/kinectv2-webserver_qt_ rel_eq__qt_external nofollow_qt__gt_https_dd_//github.com/peted70/kinectv2-webserver_lt_/a_gt__co_ but I do not think I can build it with Visual Studio Code.  After getting no where_co_ decided to just start with a new / empty .Net core 2.0 app &amp_sm_ start adding stuff from the  REPO.  Did not get very far.  As soon as I added some using statements_co_ I got error adding _t_using System.Windows.Media_t_.  After searching web_co_ found it needed a reference to _t_PresentationCore_t__co_ which I found in the _lt_a href_eq__qt_https_dd_//github.com/peted70/kinectv2-webserver/blob/master/KinectWebServer/KinectWebServer.csproj#L46_qt_ rel_eq__qt_external nofollow_qt__gt_repo_lt_/a_gt_.  I added the section to my .csproj_co_ but that got rejected.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tI don_t_t think this is going to work for .Net Core_co_ which is command line.  Why would you need graphics for a command line program was probably the thinking? .Net Core is the only thing that runs in Visual Studio Code_co_ not _qt_.Net regular_qt__co_ so unless I can find &amp_sm_ remove the section of the program that needs this_co_ I am going to have to go the Node.js route._lt_a class_eq__qt_ipsAttachLink ipsAttachLink_image_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/uploads/monthly_2017_12/image.png.f8da7ebc5af3cde029ffb2e87468f2e5.png_qt_ data-fileid_eq__qt_16121_qt_ rel_eq__qt__qt__gt__lt_img class_eq__qt_ipsImage ipsImage_thumbnailed_qt_ data-fileid_eq__qt_16121_qt_ src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/monthly_2017_12/image.thumb.png.d6f04c3c8f8af667239a877ef8227f66.png_qt_ alt_eq__qt_image.thumb.png.d6f04c3c8f8af667239a877ef8227f66.png_qt_ /_gt__lt_/a_gt__lt_span_gt_ _lt_/span_gt_\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"JCPalmer","Date":"2017-12-08T18:12:59Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tFirst _lt_a contenteditable_eq__qt_false_qt_ data-ipshover_eq__qt__qt_ data-ipshover-target_eq__qt_http_dd_//www.html5gamedevs.com/profile/11286-dbawel/?do_eq_hovercard_qt_ data-mentionid_eq__qt_11286_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/profile/11286-dbawel/_qt_ rel_eq__qt__qt__gt_@dbawel_lt_/a_gt__co_ I hope you are OK.  Yesterday on the evening news_co_ the small place you mentioned you live_co_ was indicated as the location of one of the Ventura county fires.  I remembered I had no idea how pronounce it_co_ which triggered my memory when I heard an odd name.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tMy Kinect adapter unit arrived yesterday_co_ but I resisted doing anything till today.  My back room was a victim of being the last room to clean for a couple of visits this year (never got beyond just dumping stuff there).  That combined with being the entrance point for a large dog made the amount of dirt even larger than I thought.  After cleaning all morning_co_ was ready to play.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tAfter hook up_co_ Kinect Studio did a successful capture.  I have more_co_ but will wait till things firm up.  Having an actual system means there are things I can actually try.\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"dbawel","Date":"2017-12-11T23:46:05Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tHey _lt_a contenteditable_eq__qt_false_qt_ data-ipshover_eq__qt__qt_ data-ipshover-target_eq__qt_http_dd_//www.html5gamedevs.com/profile/8492-jcpalmer/?do_eq_hovercard_qt_ data-mentionid_eq__qt_8492_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/profile/8492-jcpalmer/_qt_ rel_eq__qt__qt__gt_@JCPalmer_lt_/a_gt_-\n_lt_/p_gt_\n\n_lt_p_gt_\n\tI actually lost my house in the _qt_Thomas_qt_ fire this past Thursday night. Not much left_co_ and just sorting through what Is potentially recognizable. However_co_ I have to be grateful as my family is all OK_co_ and my pets as well. Stuff can always be replaced. After something like this_co_ it really puts my life into perspective. I just happy for what I do have. Thanks for asking and thinking about me and my family.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tAs for the Kinect V2_co_ my current task is much simpler to begin with_co_ and perhaps _lt_a contenteditable_eq__qt_false_qt_ data-ipshover_eq__qt__qt_ data-ipshover-target_eq__qt_http_dd_//www.html5gamedevs.com/profile/4442-deltakosh/?do_eq_hovercard_qt_ data-mentionid_eq__qt_4442_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/profile/4442-deltakosh/_qt_ rel_eq__qt__qt__gt_@Deltakosh_lt_/a_gt_ might be able to help. I just need to connect 8 - 10 Kinect V2 units together in an array and use these in an array to detect where an object such as a ball touches the wall with a projector projecting the render canvas onto the wall - and detect where the ball hits the wall to return a relative X_co_Y position on the canvas to use as a control point. The best example would be that I have objects flying around in the render canvas_co_ and when a ball hits the wall and intersects an object on the render canvas at the corresponding X_co_Y position_co_ then the object is destroyed. Any thoughts from anyone on how I might link more than one Kinect V2 together to cover a 36ft. X 10ft. projected canvas_sm_ and is there currently a limitation as to how many Kinect V2s can be currently linked together in a single array which can register a relative reasonable X_co_Y position to then affect the objects on the render canvas? I_t_ve not done this yet_co_ so I would appreciate any help at all with this.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tIf I can get this to work_co_ then I will be able to get a large company I_t_m working for to switch from Three.js to Babylon.js for the future and commit to Babylon.js for all of their online game content in the future_sm_ and this is one of the 3 largest game companies in the world which I now haw considerable influence. But only if I am able to deliver content in the coming months to meet their needs. I_t_m confident I can do this myself_co_ however_co_ I_t_m not so confident I can get it done in the short few weeks I have to deliver. So please help if you have any ideas or experience in how I might approach this or have any code examples to point me in the right direction.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tAgain_co_ than you for asking about my family and personal safety_co_ as I barely got out with my family and pets before the house literally exploded. But I just started a great job_co_ and have my family and all I really need to be happy - as stuff is only stuff. And I just bought the brand new Microsoft Surface 2 laptop with the NVidea 1060 graphics card with 8 GB ram and 1 TB of Solid State Drive for memory. It cost almost $3500.00_co_ but so well worth it! This machine is a monster! I_t_ve yet to work on a new desktop that can out-perform this beast - and it only weighs 1.7 lbs if you remove the keyboard - and the screen is absolutely beautiful. Even if you can_t_t afford it_co_ buy it - as you_t_ll work that much faster and that much easier that it will easily pay for itself.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tAnyway_co_ please let me know any thoughts all you devs might have. I could really use the great brains on this forum right now_co_ as mine are all but spent.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tCheers_co_\n_lt_/p_gt_\n\n_lt_p_gt_\n\tDB\n_lt_/p_gt_\n\n_lt_p_gt_\n\t \n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"JCPalmer","Date":"2017-12-12T18:00:05Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tThat_t_s brutal.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tAs far as your _qt_Kinect array_qt__co_ think you should start at both ends_co_ and try to see if you can make them meet _qt_on paper_qt__co_ first.  From the hardware side_co_ you clearly need more than one computer.  Each Kinect is going to need a USB 3.  I recall that you can have Multiple kinect systems can be on a single machine. I do not recall the limit_co_ but as you indicate_co_ 8 seems way high.  As production of Kinect stopped in Oct 2017_co_ your use of the word _qt_currently_qt_ in relation to the limitation_co_ seems more _qt_final_qt_ to me_co_ at the SDK level.  Also_co_ the amount of data transferred for each sensor_co_ could put a big load on each system_co_ limiting that way as well.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tFrom the other side_co_ you clearly want one scene (on one machine ).  Since web sockets are the only way into browser based Javascript anyway_co_ you could listen on multiple ports on a small lan of all the machines. \n_lt_/p_gt_\n\n_lt_p_gt_\n\tJust start filling in what the final scene wants_co_ &amp_sm_ what _qt_Kinect offers_qt_.  I have looked at the source of the node based solution from the old thread_co_ and see that it is using a _lt_a href_eq__qt_https_dd_//github.com/wouterverweirder/kinect2/blob/master/src/kinect2.cc#L130_qt_ rel_eq__qt_external nofollow_qt__gt_single _qt_default_qt_ kinect_lt_/a_gt_.  I am not so sure trying to get more than one sensor per computer is not a trap.  That_t_s all I got.  I am not doing anything like this.\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"JCPalmer","Date":"2017-12-15T20:56:40Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tAlright_co_ I am now ready to say what I am going to do after much exploration.  I am going to have a small body tracking command line program / DLL program_dd_\n_lt_/p_gt_\n\n_lt_ul_gt__lt_li_gt_\n\t\tRun as a command line program_co_ as a socket server when going to WebGL (implemented later)\n\t_lt_/li_gt_\n\t_lt_li_gt_\n\t\tRun as Dynamic Linked Library when animating in Blender.\n\t_lt_/li_gt_\n_lt_/ul_gt__lt_p_gt_\n\tThe output either way is going to be JSON.  Javascript &amp_sm_ Python have very fast parsers.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tI looked at many things from directly referencing Microsoft.Kinect.dll inside of Blender_co_ to C# &amp_sm_ node implementations.  They all required tons of extra stuff_dd_  like nest libraries to handle com objects in python.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tI ended up starting with this _lt_a href_eq__qt_https_dd_//gist.github.com/Palmer-JC/fc786799338bd1c9659bd1ff72c802c4_qt_ rel_eq__qt_external nofollow_qt__gt_gist _lt_/a_gt_I found_co_ which was not filled up with tons of garbage.  Right now it is has a main_co_ and I am successfully compiling_co_ running_co_ and outputting to console.  Want to break into 2 source files_co_ one with a main &amp_sm_ future socket server (console writer for now)_co_ and one which does body tracking.  Also need to start using a thread &amp_sm_ callbacks.  Here is how the MakeHuman Blender add-in looks below.  (The recording controls are just mockups at present). \n_lt_/p_gt_\n\n_lt_p_gt_\n\tMy effort will be to get tracking working for Blender.  Blender is more important to me as I can then use its facilities to key frame reduce. \n_lt_/p_gt_\n\n_lt_p_gt_\n\t_lt_a class_eq__qt_ipsAttachLink ipsAttachLink_image_qt_ data-fileid_eq__qt_16262_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/uploads/monthly_2017_12/5a3436ef3cfb5_communitytab.JPG.7d5158dfc36d85464997c11c7b7c47bf.JPG_qt_ rel_eq__qt__qt__gt__lt_img alt_eq__qt_5a3436ef41d2a_communitytab.thumb.JPG.d1627684c869d9a582122ea518660f60.JPG_qt_ class_eq__qt_ipsImage ipsImage_thumbnailed_qt_ data-fileid_eq__qt_16262_qt_ src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/monthly_2017_12/5a3436ef41d2a_communitytab.thumb.JPG.d1627684c869d9a582122ea518660f60.JPG_qt_ /_gt__lt_/a_gt_\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"JCPalmer","Date":"2017-12-20T20:31:21Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tWell_co_ I have the preliminary program_co_ generating JSON out to console.  It is a simple 3 source file visual studio c++ project_co_ as below_dd_\n_lt_/p_gt_\n\n_lt_ul_gt__lt_li_gt_\n\t\tCommon ConsoleKinect.h file_co_ 42 lines\n\t_lt_/li_gt_\n\t_lt_li_gt_\n\t\tConsoleKinect.cpp to connect / disconnect to sensor.  It also has a main() which writes JSON to console_co_ 79 lines.  Could maybe be changed to web sockets.\n\t_lt_/li_gt_\n\t_lt_li_gt_\n\t\tBodyTracking.cpp which sends JSON of up to 6 bodies to a callback function_co_ 276 lines. One frame below (in decimeters)_dd_\n\t_lt_/li_gt_\n_lt_/ul_gt__lt_pre_gt_\n_lt_code_gt_{                                                                                             \n_qt_floorClipPlane_qt__dd_ {_qt_x_qt__dd_-0.069041_co__qt_y_qt__dd_0.977668_co__qt_z_qt__dd_0.198492_co__qt_w_qt__dd_0.000000}_co_                     \n_qt_bodies_qt__dd_ [                                                                                   \n        {                                                                                     \n        _qt_id_qt__dd_ 72057594037966008_co_                                                              \n        _qt_bones_qt__dd_ {                                                                            \n                _qt_SpineBase_qt__dd_ {                                                                \n                        _qt_state_qt__dd_ _qt_Tracked_qt__co_                                                   \n                        _qt_location_qt__dd_ {_qt_x_qt__dd_-7.602520_co__qt_y_qt__dd_-2.450854_co__qt_z_qt__dd_12.575587}_co_              \n                        _qt_rotation_qt__dd_ {_qt_x_qt__dd_-0.038790_co__qt_y_qt__dd_0.984983_co__qt_z_qt__dd_-0.007158_co__qt_w_qt__dd_-0.168086}  \n                }_co_                                                                            \n                _qt_SpineMid_qt__dd_ {                                                                 \n                        _qt_state_qt__dd_ _qt_Tracked_qt__co_                                                   \n                        _qt_location_qt__dd_ {_qt_x_qt__dd_-7.874529_co__qt_y_qt__dd_0.989391_co__qt_z_qt__dd_12.571926}_co_               \n                        _qt_rotation_qt__dd_ {_qt_x_qt__dd_-0.038751_co__qt_y_qt__dd_0.984069_co__qt_z_qt__dd_-0.007366_co__qt_w_qt__dd_-0.173358}  \n                }_co_                                                                            \n                _qt_Neck_qt__dd_ {                                                                     \n                        _qt_state_qt__dd_ _qt_Tracked_qt__co_                                                   \n                        _qt_location_qt__dd_ {_qt_x_qt__dd_-8.050920_co__qt_y_qt__dd_4.244757_co__qt_z_qt__dd_12.405807}_co_               \n                        _qt_rotation_qt__dd_ {_qt_x_qt__dd_-0.011741_co__qt_y_qt__dd_0.983150_co__qt_z_qt__dd_-0.042320_co__qt_w_qt__dd_-0.177447}  \n                }_co_                                                                            \n                _qt_Head_qt__dd_ {                                                                     \n                        _qt_state_qt__dd_ _qt_Tracked_qt__co_                                                   \n                        _qt_location_qt__dd_ {_qt_x_qt__dd_-8.169784_co__qt_y_qt__dd_5.621467_co__qt_z_qt__dd_12.831615}_co_               \n                        _qt_rotation_qt__dd_ {_qt_x_qt__dd_0.000000_co__qt_y_qt__dd_0.000000_co__qt_z_qt__dd_0.000000_co__qt_w_qt__dd_0.000000}     \n                }_co_                                                                            \n                _qt_ShoulderLeft_qt__dd_ {                                                             \n                        _qt_state_qt__dd_ _qt_Inferred_qt__co_                                                  \n                        _qt_location_qt__dd_ {_qt_x_qt__dd_-9.356917_co__qt_y_qt__dd_3.143413_co__qt_z_qt__dd_12.689640}_co_               \n                        _qt_rotation_qt__dd_ {_qt_x_qt__dd_0.780255_co__qt_y_qt__dd_-0.620334_co__qt_z_qt__dd_-0.053141_co__qt_w_qt__dd_0.059698}   \n                }_co_                                                                            \n                _qt_ElbowLeft_qt__dd_ {                                                                \n                        _qt_state_qt__dd_ _qt_Inferred_qt__co_                                                  \n                        _qt_location_qt__dd_ {_qt_x_qt__dd_-10.125637_co__qt_y_qt__dd_0.933223_co__qt_z_qt__dd_12.700338}_co_              \n                        _qt_rotation_qt__dd_ {_qt_x_qt__dd_-0.504695_co__qt_y_qt__dd_0.087254_co__qt_z_qt__dd_0.847071_co__qt_w_qt__dd_0.141917}    \n                }_co_                                                                            \n                _qt_WristLeft_qt__dd_ {                                                                \n                        _qt_state_qt__dd_ _qt_Inferred_qt__co_                                                  \n                        _qt_location_qt__dd_ {_qt_x_qt__dd_-9.458263_co__qt_y_qt__dd_3.967202_co__qt_z_qt__dd_12.008181}_co_               \n                        _qt_rotation_qt__dd_ {_qt_x_qt__dd_-0.085888_co__qt_y_qt__dd_0.203032_co__qt_z_qt__dd_-0.126433_co__qt_w_qt__dd_0.967169}   \n                }_co_                                                                            \n                _qt_HandLeft_qt__dd_ {                                                                 \n                        _qt_state_qt__dd_ _qt_Inferred_qt__co_                                                  \n                        _qt_location_qt__dd_ {_qt_x_qt__dd_-8.712178_co__qt_y_qt__dd_4.470363_co__qt_z_qt__dd_11.882681}_co_               \n                        _qt_rotation_qt__dd_ {_qt_x_qt__dd_0.033128_co__qt_y_qt__dd_0.206811_co__qt_z_qt__dd_-0.471186_co__qt_w_qt__dd_0.856806}    \n                }_co_                                                                            \n                _qt_ShoulderRight_qt__dd_ {                                                            \n                        _qt_state_qt__dd_ _qt_Tracked_qt__co_                                                   \n                        _qt_location_qt__dd_ {_qt_x_qt__dd_-6.881767_co__qt_y_qt__dd_1.855229_co__qt_z_qt__dd_11.495045}_co_               \n                        _qt_rotation_qt__dd_ {_qt_x_qt__dd_0.905937_co__qt_y_qt__dd_0.326226_co__qt_z_qt__dd_-0.209925_co__qt_w_qt__dd_-0.169664}   \n                }_co_                                                                            \n                _qt_ElbowRight_qt__dd_ {                                                               \n                        _qt_state_qt__dd_ _qt_Tracked_qt__co_                                                   \n                        _qt_location_qt__dd_ {_qt_x_qt__dd_-6.203947_co__qt_y_qt__dd_-0.852729_co__qt_z_qt__dd_11.262550}_co_              \n                        _qt_rotation_qt__dd_ {_qt_x_qt__dd_0.950260_co__qt_y_qt__dd_0.128880_co__qt_z_qt__dd_-0.283492_co__qt_w_qt__dd_-0.005223}   \n                }_co_                                                                            \n                _qt_WristRight_qt__dd_ {                                                               \n                        _qt_state_qt__dd_ _qt_Tracked_qt__co_                                                   \n                        _qt_location_qt__dd_ {_qt_x_qt__dd_-6.054850_co__qt_y_qt__dd_-3.174261_co__qt_z_qt__dd_11.341275}_co_              \n                        _qt_rotation_qt__dd_ {_qt_x_qt__dd_0.951029_co__qt_y_qt__dd_0.025301_co__qt_z_qt__dd_-0.306971_co__qt_w_qt__dd_0.025948}    \n                }_co_                                                                            \n                _qt_HandRight_qt__dd_ {                                                                \n                        _qt_state_qt__dd_ _qt_Tracked_qt__co_                                                   \n                        _qt_location_qt__dd_ {_qt_x_qt__dd_-6.148480_co__qt_y_qt__dd_-3.594989_co__qt_z_qt__dd_11.472821}_co_              \n                        _qt_rotation_qt__dd_ {_qt_x_qt__dd_0.939234_co__qt_y_qt__dd_-0.144842_co__qt_z_qt__dd_-0.290934_co__qt_w_qt__dd_0.110530}   \n                }_co_                                                                            \n                _qt_HipLeft_qt__dd_ {                                                                  \n                        _qt_state_qt__dd_ _qt_Tracked_qt__co_                                                   \n                        _qt_location_qt__dd_ {_qt_x_qt__dd_-8.223284_co__qt_y_qt__dd_-2.363104_co__qt_z_qt__dd_12.518145}_co_              \n                        _qt_rotation_qt__dd_ {_qt_x_qt__dd_-0.655357_co__qt_y_qt__dd_0.753883_co__qt_z_qt__dd_-0.028560_co__qt_w_qt__dd_0.036759}   \n                }_co_                                                                            \n                _qt_KneeLeft_qt__dd_ {                                                                 \n                        _qt_state_qt__dd_ _qt_Tracked_qt__co_                                                   \n                        _qt_location_qt__dd_ {_qt_x_qt__dd_-8.740862_co__qt_y_qt__dd_-5.240495_co__qt_z_qt__dd_13.740103}_co_              \n                        _qt_rotation_qt__dd_ {_qt_x_qt__dd_0.687393_co__qt_y_qt__dd_0.081403_co__qt_z_qt__dd_0.693923_co__qt_w_qt__dd_0.198332}     \n                }_co_                                                                            \n                _qt_AnkleLeft_qt__dd_ {                                                                \n                        _qt_state_qt__dd_ _qt_Inferred_qt__co_                                                  \n                        _qt_location_qt__dd_ {_qt_x_qt__dd_-8.586180_co__qt_y_qt__dd_-5.091630_co__qt_z_qt__dd_10.653872}_co_              \n                        _qt_rotation_qt__dd_ {_qt_x_qt__dd_0.485320_co__qt_y_qt__dd_0.539348_co__qt_z_qt__dd_-0.490311_co__qt_w_qt__dd_-0.482870}   \n                }_co_                                                                            \n                _qt_FootLeft_qt__dd_ {                                                                 \n                        _qt_state_qt__dd_ _qt_Inferred_qt__co_                                                  \n                        _qt_location_qt__dd_ {_qt_x_qt__dd_-8.778518_co__qt_y_qt__dd_-4.952463_co__qt_z_qt__dd_9.319104}_co_               \n                        _qt_rotation_qt__dd_ {_qt_x_qt__dd_0.000000_co__qt_y_qt__dd_0.000000_co__qt_z_qt__dd_0.000000_co__qt_w_qt__dd_0.000000}     \n                }_co_                                                                            \n                _qt_HipRight_qt__dd_ {                                                                 \n                        _qt_state_qt__dd_ _qt_Tracked_qt__co_                                                   \n                        _qt_location_qt__dd_ {_qt_x_qt__dd_-6.598404_co__qt_y_qt__dd_-2.416044_co__qt_z_qt__dd_11.948594}_co_              \n                        _qt_rotation_qt__dd_ {_qt_x_qt__dd_0.665414_co__qt_y_qt__dd_0.693741_co__qt_z_qt__dd_-0.206221_co__qt_w_qt__dd_-0.182811}   \n                }_co_                                                                            \n                _qt_KneeRight_qt__dd_ {                                                                \n                        _qt_state_qt__dd_ _qt_Inferred_qt__co_                                                  \n                        _qt_location_qt__dd_ {_qt_x_qt__dd_-7.947070_co__qt_y_qt__dd_-5.174057_co__qt_z_qt__dd_11.059258}_co_              \n                        _qt_rotation_qt__dd_ {_qt_x_qt__dd_0.815460_co__qt_y_qt__dd_-0.261802_co__qt_z_qt__dd_0.516198_co__qt_w_qt__dd_-0.004877}   \n                }_co_                                                                            \n                _qt_AnkleRight_qt__dd_ {                                                               \n                        _qt_state_qt__dd_ _qt_Inferred_qt__co_                                                  \n                        _qt_location_qt__dd_ {_qt_x_qt__dd_-9.306696_co__qt_y_qt__dd_-7.740426_co__qt_z_qt__dd_10.477659}_co_              \n                        _qt_rotation_qt__dd_ {_qt_x_qt__dd_0.751671_co__qt_y_qt__dd_-0.248703_co__qt_z_qt__dd_0.606808_co__qt_w_qt__dd_0.070159}    \n                }_co_                                                                            \n                _qt_FootRight_qt__dd_ {                                                                \n                        _qt_state_qt__dd_ _qt_Inferred_qt__co_                                                  \n                        _qt_location_qt__dd_ {_qt_x_qt__dd_-9.703592_co__qt_y_qt__dd_-7.874325_co__qt_z_qt__dd_9.320196}_co_               \n                        _qt_rotation_qt__dd_ {_qt_x_qt__dd_0.000000_co__qt_y_qt__dd_0.000000_co__qt_z_qt__dd_0.000000_co__qt_w_qt__dd_0.000000}     \n                }_co_                                                                            \n                _qt_SpineShoulder_qt__dd_ {                                                            \n                        _qt_state_qt__dd_ _qt_Tracked_qt__co_                                                   \n                        _qt_location_qt__dd_ {_qt_x_qt__dd_-8.020656_co__qt_y_qt__dd_3.453608_co__qt_z_qt__dd_12.468588}_co_               \n                        _qt_rotation_qt__dd_ {_qt_x_qt__dd_-0.025380_co__qt_y_qt__dd_0.983288_co__qt_z_qt__dd_-0.025873_co__qt_w_qt__dd_-0.178415}  \n                }_co_                                                                            \n                _qt_HandTipLeft_qt__dd_ {                                                              \n                        _qt_state_qt__dd_ _qt_Inferred_qt__co_                                                  \n                        _qt_location_qt__dd_ {_qt_x_qt__dd_-8.550290_co__qt_y_qt__dd_4.696713_co__qt_z_qt__dd_11.654633}_co_               \n                        _qt_rotation_qt__dd_ {_qt_x_qt__dd_0.000000_co__qt_y_qt__dd_0.000000_co__qt_z_qt__dd_0.000000_co__qt_w_qt__dd_0.000000}     \n                }_co_                                                                            \n                _qt_ThumbLeft_qt__dd_ {                                                                \n                        _qt_state_qt__dd_ _qt_Inferred_qt__co_                                                  \n                        _qt_location_qt__dd_ {_qt_x_qt__dd_-8.642012_co__qt_y_qt__dd_4.133314_co__qt_z_qt__dd_11.844402}_co_               \n                        _qt_rotation_qt__dd_ {_qt_x_qt__dd_0.000000_co__qt_y_qt__dd_0.000000_co__qt_z_qt__dd_0.000000_co__qt_w_qt__dd_0.000000}     \n                }_co_                                                                            \n                _qt_HandTipRight_qt__dd_ {                                                             \n                        _qt_state_qt__dd_ _qt_Tracked_qt__co_                                                   \n                        _qt_location_qt__dd_ {_qt_x_qt__dd_-6.172046_co__qt_y_qt__dd_-4.336384_co__qt_z_qt__dd_11.558290}_co_              \n                        _qt_rotation_qt__dd_ {_qt_x_qt__dd_0.000000_co__qt_y_qt__dd_0.000000_co__qt_z_qt__dd_0.000000_co__qt_w_qt__dd_0.000000}     \n                }_co_                                                                            \n                _qt_ThumbRight_qt__dd_ {                                                               \n                        _qt_state_qt__dd_ _qt_Tracked_qt__co_                                                   \n                        _qt_location_qt__dd_ {_qt_x_qt__dd_-6.375901_co__qt_y_qt__dd_-3.567194_co__qt_z_qt__dd_10.899231}_co_              \n                        _qt_rotation_qt__dd_ {_qt_x_qt__dd_0.000000_co__qt_y_qt__dd_0.000000_co__qt_z_qt__dd_0.000000_co__qt_w_qt__dd_0.000000}     \n                }                                                                             \n        }                                                                                     \n]                                                                                             \n}                                                                                                                                                         _lt_/code_gt__lt_/pre_gt_\n\n_lt_p_gt_\n\tThere are only 4 entry points_co_ which are as simple as possible for Python_dd_\n_lt_/p_gt_\n\n_lt_pre_gt_\n_lt_code_gt_// entry points of ConsoleKinect.cpp\nDllExport HRESULT openSensor(char Left_or_Righthanded_co_ char Forward_or_Mirror_co_ char Decimeters_Meters_or_Inches)_sm_\nDllExport void closeSensor()_sm_\n\n// entry points BodyTracking.cpp\nDllExport HRESULT beginBodyTracking( void(*cb)(char *) )_sm_\nDllExport void endBodyTracking()_sm_\n_lt_/code_gt__lt_/pre_gt_\n\n_lt_p_gt_\n\tWill start tomorrow trying to get Blender to first call then use the information. _lt_a contenteditable_eq__qt_false_qt_ data-ipshover_eq__qt__qt_ data-ipshover-target_eq__qt_http_dd_//www.html5gamedevs.com/profile/11286-dbawel/?do_eq_hovercard_qt_ data-mentionid_eq__qt_11286_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/profile/11286-dbawel/_qt_ rel_eq__qt__qt__gt_@dbawel_lt_/a_gt__co_ I do not know which reader you need_co_ possible color if you have a special colored ball_co_ you might use BodyTracker.cpp as a template.  Everything that be borrowed from on the web jams all readers into one completely unreadable file_co_ like _lt_a href_eq__qt_https_dd_//github.com/wouterverweirder/kinect2/blob/master/src/kinect2.cc_qt_ rel_eq__qt_external nofollow_qt__gt_this_lt_/a_gt_.  That is only helpful when you need to use a multi-source reader.  Thank god_co_ I do not need anything but one.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tI do not yet have a place where the source lives on the net.  Mixing a c++ project with anything else seems like a bad idea.\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"dbawel","Date":"2017-12-21T03:25:54Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tHi _lt_a contenteditable_eq__qt_false_qt_ data-ipshover_eq__qt__qt_ data-ipshover-target_eq__qt_http_dd_//www.html5gamedevs.com/profile/8492-jcpalmer/?do_eq_hovercard_qt_ data-mentionid_eq__qt_8492_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/profile/8492-jcpalmer/_qt_ rel_eq__qt__qt__gt_@JCPalmer_lt_/a_gt_ -\n_lt_/p_gt_\n\n_lt_p_gt_\n\tI agree completely - this could become an extremely difficult task due to the source we_t_re working with on so many different levels. And I_t_ve only seen successful applications for the Kinect V2 written using Python_co_ as it_t_s the most compatible wrap around language available which has many of the functions necessary already written into the API. Regardless_co_ we_t_re most likely looking at something quite messy if I rquire anything beyond _qt_simple._qt_\n_lt_/p_gt_\n\n_lt_p_gt_\n\tAnd you nailed the features I initially need for my current project. I need to track different colored _qt_bean bags_qt_ or small bags with some weight behind them which will be thrown at a projected image on a wall. So the info you_t_ve provided gives me a starting place_co_ and I can use all the help I can get in the coming weeks. So far_co_ it appears d-able_sm_ however_co_ I have little experience with more than 2 Kinect units_co_ and have used primarily the basic functions clearly written and easily accessible through the SDK. So if you have time to assist_co_ I might really need the help. After this_co_ then I_t_d like to try and implement a real-time capture volume using more than one Kinect V2 - however_co_ I do know what this will require_co_ and it_t_s quite a bit above my pay grade. But I_t_ll cross that bridge soon - perhaps real soon - but I absolutely need to track 10 - 12 different colored bean filled bags or spheres in order to get the current project finished - and finished on time which is before March 1st.\n_lt_/p_gt_\n\n_lt_p_gt_\n\t I_t_ve been looking at all resources online_co_ as there has been a good bit of work done using three.js_co_ but there_t_s not any projects which the developers provide all of the code - which I certainly understand as the wok that_t_s been done is certainly no small task_co_ and definitely worth revenue as many developers using three.js have been asking to use the code. But first_co_ I_t_m looking for info such as the limits for opening and maintaining a Web Socket connection between multiple Kinect V2s -which I_t_ve yet to find out how many Kinects can currently be connected at any given time. The limit used to be 8_co_ however_co_ I_t_m not certain if this limit still exists_co_ or what work has been accomplished since the release of the V2 and other peripherals which might help maintaining the connections over time. So if you know of any resources concerning these and other areas of new development_co_ I_t_d love to share whatever I_t_ve discovered_co_ and possibly embark on a project to make the most use of depth maps for imaging devices such as the Kinect. One advantage I do have is that I_t_m part of a group of many of the best engineers and developers anywhere in the world_co_ as we_t_re writing most of the applications for Sony devices_sm_ and I personally work on the R&amp_sm_D side of Sony where we get to push the envelope as far as we possibly can. Needless to say_co_ I love my job - possibly more than any job in my recent past. But I can make use of many of these resources as needed_co_ which provides me with advantages few others have in any industry - as Sony is definately leading in the areas of smart phones and most all other entertainment devices.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tSo let me know what you might think about all of the above_co_ and I_t_d love to consider what we might be able to pull together in search of new applications few have ever considered designing - yet building. This is why I often work with _lt_a contenteditable_eq__qt_false_qt_ data-ipshover_eq__qt__qt_ data-ipshover-target_eq__qt_http_dd_//www.html5gamedevs.com/profile/19199-pryme8/?do_eq_hovercard_qt_ data-mentionid_eq__qt_19199_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/profile/19199-pryme8/_qt_ rel_eq__qt__qt__gt_@Pryme8_lt_/a_gt_ - as he has never been afraid to push the barriers of practically anything - and usually if not always able to deliver on his ideas. He just needs someone like me to push him through to the end_co_ as his attention span is extremely low_co_ since he knows he is able to accomplish most everything he sets out to do - and that_t_s a dangerous place in which to allow your mind to live. Anyway_co_ I mentioned him as I_t_m looking for others to join our small team of _qt_thinkers_qt_ who aren_t_t afraid to push way outside of what_t_s currently considered _qt_do-able._qt_ And you seem to be living in that world as well_sm_ while there are very few of us who are willing to go there. Just let me know what you think_co_ and I_t_m sure I_t_ll hear from _lt_a contenteditable_eq__qt_false_qt_ data-ipshover_eq__qt__qt_ data-ipshover-target_eq__qt_http_dd_//www.html5gamedevs.com/profile/19199-pryme8/?do_eq_hovercard_qt_ data-mentionid_eq__qt_19199_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/profile/19199-pryme8/_qt_ rel_eq__qt__qt__gt_@Pryme8_lt_/a_gt_ the moment he reads what I_t_ve written above. Not to mention I_t_ll definitely give him a call this weekend_co_ as he might be able to assist with the various barriers I have in front of me which I must solve and put into production within weeks. But that_t_s where I find the most _qt_fun_qt_ in any aspect of technology_co_ and where I_t_ve been able to accomplish the most. It_t_s places like this where I brought the Matrix to life as well as Gollum - and people often marvel about Avatar - however_co_ most everything we did to accomplish Avatar was already a decade old and developed for films such as the first Mortal Kombat movie among other projects overlooked due to the times or often due to their audience. But it_t_s been exciting for me personally_co_ although it_t_s often reported that we broke technical barriers on Avatar_sm_ whereas the real truth is that we had already developed and used the technologies years before Jim ever conceived of the script - but that_t_s another story.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tAgain_co_ let me know your thoughts as you appear to be interested in looking into this further. It_t_s now after 7pm here in San Diego_co_ and I have a presentation tomorrow which I_t_m just beginning to build now. I_t_m just praying that I remember enough to push through the night and _qt_sell_qt_ this WebGL framework by tomorrow morning. No more syntax errors_co_ and no more Chrome. Only FireFox tonight as I can_t_t afford any browser errors which aren_t_t purely due to poor development skills._lt_img alt_eq__qt__dd_wacko_dd__qt_ data-emoticon_eq__qt__qt_ src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/default_wacko.png_qt_ title_eq__qt__dd_wacko_dd__qt_ /_gt_ If there_t_s an error_co_ then I need to know it_t_s me...\n_lt_/p_gt_\n\n_lt_p_gt_\n\tCheers_co_\n_lt_/p_gt_\n\n_lt_p_gt_\n\tDB\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"JCPalmer","Date":"2017-12-22T20:58:04Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tWell_co_ about to break for xmas.  I have data spilling into blender_co_ though I have to call the functions in the DLL right now by ordinal #.  Think it may have something to do with the namespace_co_ but there is only 4 entry points_co_ so good enough for now.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tThe data I am getting back is inside a _lt_strong_gt_b_t__lt_/strong_gt__lt_span style_eq__qt_color_dd_#27ae60_sm__qt__gt__lt_em_gt_mystuff_lt_/em_gt__lt_/span_gt__lt_strong_gt__t_.  _lt_/strong_gt_If that was the only problem_co_ I could just chop 2 from the front_co_ and 1 off the back.  The other issue is my escape characters \\n \\t_t_s are literals.  I hope the Json parser can ignore them_co_ or maybe they just show up that way in the Blender console.  These are not major problems.  This is as far as I got.  Kinda of making notes for myself_co_ as no one is going to read this.  _lt_a contenteditable_eq__qt_false_qt_ data-ipshover_eq__qt__qt_ data-ipshover-target_eq__qt_http_dd_//www.html5gamedevs.com/profile/11286-dbawel/?do_eq_hovercard_qt_ data-mentionid_eq__qt_11286_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/profile/11286-dbawel/_qt_ rel_eq__qt__qt__gt_@dbawel_lt_/a_gt__co_ I really did not get a good look at your long note yet. After xmas.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tHere is what my print statements to Blender console show (did a couple of line breaks &amp_sm_ shortened)_dd_\n_lt_/p_gt_\n\n_lt_pre_gt_\n_lt_code_gt_C_dd_\\Users\\Jeff Palmer\\AppData\\Roaming\\Blender Foundation\\Blender\\2.79\\scripts\\addons\\MH_Community\\kinect_sensor\\ConsoleKinect_x64.dll\nHRESULT from openSensor_dd_ 0\nHRESULT from beginBodyTracking_dd_ 0\nlength of data_dd_ 4468\nb_t_{\\n_qt_floorClipPlane_qt__dd_ {_qt_x_qt__dd_-0.066457_co__qt_y_qt__dd_0.977163_co__qt_z_qt__dd_0.201832_co__qt_w_qt__dd_0.000000}_co_\\n\n_qt_bodies_qt__dd_ [\\n\\t{\\n\\t_qt_id_qt__dd_ 72057594037991404_co_\\n\n\\t_qt_bones_qt__dd_ {\\n\\t\\t_qt_SpineBase_qt__dd_ {\\n\\t\\t\\t_qt_state_qt__dd_ _qt_Tracked_qt__co_\\n\\t\\t\\t_qt_location_qt__dd_ {_qt_x_qt__dd_0.227578_co__qt_y_qt__dd_-0.296393_co__qt_z_qt__dd_1.874896}_co_\\n\\t\\t\\t_qt_rotation_qt__dd_ {_qt_x_qt__dd_-0.082223_co__qt_y_qt__dd_0.993997_co__qt_z_qt__dd_-0.003135_co__qt_w_qt__dd_-0.072109}\\n\\t\\t}_co_\\n\\t\\t\n_qt_SpineMid_qt__dd_ {\\n\\t\\t\\t_qt_state_qt__dd_ _qt_Tracked_qt__co_\\n\\t\\t\\t_qt_location_qt__dd_ {_qt_x_qt__dd_0.177004_co__qt_y_qt__dd_0.007977_co__qt_z_qt__dd_1.876632}_co_\\n\\t\\t\\t_qt_rotation_qt__dd_ {_qt_x_qt__dd_-0.082180_co__qt_y_qt__dd_0.993055_co__qt_z_qt__dd_-0.004126_co__qt_w_qt__dd_-0.084086}\\n\\t\\t}_co_\n...\n\\n\\t\\t_qt_ThumbRight_qt__dd_ {\\n\\t\\t\\t_qt_state_qt__dd_ _qt_Tracked_qt__co_\\n\\t\\t\\t_qt_location_qt__dd_ {_qt_x_qt__dd_-0.398474_co__qt_y_qt__dd_0.266390_co__qt_z_qt__dd_1.821667}_co_\\n\\t\\t\\t_qt_rotation_qt__dd_ {_qt_x_qt__dd_0.000000_co__qt_y_qt__dd_0.000000_co__qt_z_qt__dd_0.000000_co__qt_w_qt__dd_0.000000}\\n\\t\\t}\\n\\t}\\n]\\n}\\n_t__lt_/code_gt__lt_/pre_gt_\n\n_lt_p_gt_\n\t \n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"dbawel","Date":"2017-12-24T00:20:14Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tHi _lt_a contenteditable_eq__qt_false_qt_ data-ipshover_eq__qt__qt_ data-ipshover-target_eq__qt_http_dd_//www.html5gamedevs.com/profile/8492-jcpalmer/?do_eq_hovercard_qt_ data-mentionid_eq__qt_8492_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/profile/8492-jcpalmer/_qt_ rel_eq__qt__qt__gt_@JCPalmer_lt_/a_gt_-\n_lt_/p_gt_\n\n_lt_p_gt_\n\tI appreciate the insight_co_ and that you_t_re even looking at the issue. I made it through my presentation at Sony_co_ and am still Senior Engineer in the Electronics division. So I must be doing something right. Let_t_s catch up when you have time. My Wife is in Thailand_co_ so I_t_m working through the holidays. Thus_co_ if you get bored or feel like you want to touch base over the holidays_co_ just shoot me message - as I want to move forward on integrating the Kinect V2 with babylon.js on a level that_t_s useful. There is so much we could use the Kinect to do_co_ that it_t_s certainly worth beginning an integration. Just capturing the skeleton as a bones controller in real-time would send babylon into a whole new arena for most all users. And this doesn_t_t appear to be that hard to do. So I_t_ll be working on a project for Sony which doesn_t_t utilize the Kinect_co_ however_co_ I_t_ll take a look at the connections over the break when I find time.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tHave a great holiday!\n_lt_/p_gt_\n\n_lt_p_gt_\n\tDB\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"JCPalmer","Date":"2017-12-25T19:01:31Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tWe are on two different tracks here. \n_lt_/p_gt_\n\n_lt_p_gt_\n\t - - - - - - - -\n_lt_/p_gt_\n\n_lt_p_gt_\n\tI changed my mind on going directly into BJS for bones for now.   It would take more dev work_co_ since I would have to implement a socket client / server as well_co_ then after I got it do work_co_ I would need to capture the results &amp_sm_ make a way to reduce frames in BJS.  Editing is built in for Blender_co_ so I only have to get it there.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tIf the data for bones proves useful though_co_ it could be a decent starting point for BJS.  If a websocket Server was put in BJS_co_ on say port 519_co_ then program(s) controlling kinect(s) could post 30 times a second on the BJS server.  Having client / server (poster / listener) this way around seems much better.  My notes / comments in the first post of this topic would change to get out of changing BABYLON.Skeleton itself.  If the conversion from global space to local could be made in C++_co_ then you could just assign the values passed to the bones.\n_lt_/p_gt_\n\n_lt_p_gt_\n\t- - - - - - - - -\n_lt_/p_gt_\n\n_lt_p_gt_\n\tFor your bean bag wall thing_co_ I would try very hard to avoid having to _qt_Track_qt_ the bags.  I the Kinects were mounted at the top of the wall pointed down ( the clipping plane would be the same as the walls if there is no accelerometer in them)_co_ then you might be able to just isolate in the reader program when &amp_sm_ where a wall strike occurred.  Only then would you need to bother sending up data to the BJS server.  BJS just listens_co_ and if something comes in_co_ sort of simulate what happens when a mouse click comes in.\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"dbawel","Date":"2017-12-26T23:31:14Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tHi _lt_a contenteditable_eq__qt_false_qt_ data-ipshover_eq__qt__qt_ data-ipshover-target_eq__qt_http_dd_//www.html5gamedevs.com/profile/8492-jcpalmer/?do_eq_hovercard_qt_ data-mentionid_eq__qt_8492_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/profile/8492-jcpalmer/_qt_ rel_eq__qt__qt__gt_@JCPalmer_lt_/a_gt_ -\n_lt_/p_gt_\n\n_lt_p_gt_\n\tYour insights are quite apparent_co_ and you have obviously thought this through further than I have at this stage. Although I have no excuse_co_ but am still sorting through my burned out house here in Ojai. Thank God I have this week off_co_ or I_t_d never get to this before the rains come. And it_t_s unbelievably messy now even before any rains.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tYour thoughts on not tracking the bags is precisely where I_t_m currently heading. I don_t_t need to know anything except when the bags come in contact with the wall. Prior to this_co_ there is no need to track where_co_ when_co_ or any other attribute of the bags. I definitely have a clear position in pixel depth when the bags hit the wall_co_ and can track this with simple acceleration/deceleration if necessary. However_co_ I_t_m certain that the depth map will provide a position in space independent of any physics which will show when each bag meets the position of the wall as the projector is projecting the image. So thanks for your insight into this_co_ as it simply re-enforces where I am currently looking at reliably returning a position for each bag thrown.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tAnd I_t_m not certain how much time you_t_ve spent with the Kinect V2_co_ but We_t_ve only got approx. an area 2 X 2 meters where we will be able to reliably track each bags position without artifact problems. So again_co_ your insight re-enforces the approach I_t_m currently taking to determine if and where a bag makes contact on the wall.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tAs for future work in tracking objects and more specifically skeletons_co_ 30 fps is definitely enough data to deliver a relatively smooth IK animation. When we began using mocap back in the early 90s (yes_co_ I know many of you were still crawling around on the floor - if even born yet)_co_ 30fps was all we had to work with. Only when we were able to increase our fps to 60 fps_co_ it was only due to the increase in processing power. However_co_ it wasn_t_t long after where we achieved 24o fps for the Matrix films in the late 90s_co_ otherwise_co_ there would be no Matrix films. So _lt_a contenteditable_eq__qt_false_qt_ data-ipshover_eq__qt__qt_ data-ipshover-target_eq__qt_http_dd_//www.html5gamedevs.com/profile/8492-jcpalmer/?do_eq_hovercard_qt_ data-mentionid_eq__qt_8492_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/profile/8492-jcpalmer/_qt_ rel_eq__qt__qt__gt_@JCPalmer_lt_/a_gt_ - I hope you continue to offer up any thoughts you have in moving this forward_co_ as with the new AR devices coming to market_co_ the Kinect and other devices to capture human bipedal motion will play a much larger role than developers realize now.  I_t_ll keep moving towards the integration of such devices (the Kinect is a first and obvious choice due to its extensive SDK) into WebGL and specifically the babylon.js framework. Thant is_co_ providing Sony allows me to keep moving forward with BJS now that it_t_s supported my Microsoft. However_co_ they_t_ve been incredibly supportive thus far - I just need them to realize why we need to continue with babylon.js and avoid the legacy traps of three.js and other frameworks.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tSo I hope we can keep the discussion and progress moving forward_co_ as I now have some resources_co_ and can make far greater progress than before on my own. So I_t_ll keep it moving forward as long as possible_co_ and hope you stay involved as well. But for now_co_ you_t_ve been a huge help_co_ and if I can assist you in any way with this or any other forward thinking innovations_co_ please message me_co_ and I_t_ll let you know what I have available as resources in moving forward.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tCheers_co_\n_lt_/p_gt_\n\n_lt_p_gt_\n\tDB\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"JCPalmer","Date":"2018-01-03T18:09:53Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tWell making progress slowly.  I assume the AR devices coming to market you meant was Magic Leap.  FYI_co_ did you see the Rolling Stone_lt_a href_eq__qt_https_dd_//www.rollingstone.com/glixel/features/lightwear-introducing-magic-leaps-mixed-reality-goggles-w514479_qt_ rel_eq__qt_external nofollow_qt__gt_ recent piece_lt_/a_gt_? Kind of a long PR article_co_ but the googles look interesting unless you need corrective glasses.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tAm not sure how AR affects this Blender integration project specifically_co_ unless Magic Leap has a Blender exporter though.  They are fairly likely to be relying on gltf_co_ but let them know I_t_ll write them an inline source code generating exporter for one for free _lt_img alt_eq__qt__dd_P_qt_ data-emoticon_eq__qt__qt_ height_eq__qt_20_qt_ src_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/default_tongue.png_qt_ srcset_eq__qt_http_dd_//www.html5gamedevs.com/uploads/emoticons/tongue@2x.png 2x_qt_ title_eq__qt__dd_P_qt_ width_eq__qt_20_qt_ /_gt_.  The exporter is multi-pass_co_ so the thing is already half written!\n_lt_/p_gt_\n\n_lt_p_gt_\n\tI have found that I need local rotations to write Blender actions_co_ so I have re-coded some of the BJS Matrix functions into C++.  If this ever gets ported for BJS_co_ then that part is already being done and in it_t_s own thread.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tThe animation is still all screwed up once in blender.  Just hopefully need to divide and conquer_dd_ the Y-Z swap_co_ and establish a baseline location of the root bone with the first frame.  Then subtract the baseline out for all the frames.  Will first do things in python_co_ and move them to the C++ side as they make the picture better.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tSpeaking of first frames_co_ most of my captures so far are me just running into the scene after I hit the record button.  I need a clean first frame.  Not that I cannot delete frames in front in Blender_co_ but the baseline location is not zeroed when I want it to be.  I have come up with an _qt_Action_qt_ pose_co_ where frames get discarded until the finger tips of both hands are wider than the shoulders of the opposite side.  This is done in C++_co_ and I even call MessageBeep() when it is triggered_co_ which is oddly very satisfying.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tFor multi-body recordings_co_ I have a UI problem.  I want to do the recording_co_ but not assign Blender actions to the individual skeletons until later.  Bringing up a list in Blender is not that easy to understand_co_ at least.  _lt_a href_eq__qt_https_dd_//blender.stackexchange.com/questions/97706/making-a-custom-list-of-kinect-data-for-later-assignment_qt_ rel_eq__qt_external nofollow_qt__gt_See_lt_/a_gt_.\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"JCPalmer","Date":"2018-01-08T19:04:11Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tHey _lt_a contenteditable_eq__qt_false_qt_ data-ipshover_eq__qt__qt_ data-ipshover-target_eq__qt_http_dd_//www.html5gamedevs.com/profile/11286-dbawel/?do_eq_hovercard_qt_ data-mentionid_eq__qt_11286_qt_ href_eq__qt_http_dd_//www.html5gamedevs.com/profile/11286-dbawel/_qt_ rel_eq__qt__qt__gt_@dbawel_lt_/a_gt__co_ this weekend I put my computer to sleep.  Saturaday_co_ I noticed by the drive light &amp_sm_ kinect sensor that it was running.  It was so cold in my back room under electric heat_co_ that I just decided to power down.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tThis morning sure enough this _lt_a href_eq__qt_https_dd_//support.microsoft.com/en-us/help/4056892/windows-10-update-kb4056892_qt_ rel_eq__qt_external nofollow_qt__gt_update _lt_/a_gt_needed to completed upon power up.  Things with Kinect changed.  First_co_ before the white light on right side on the Kinect was always on when the computer was on.  Now it is only on when sensor was open &amp_sm_ acquiring data.  That does not sound bad_co_ but it is different.  Since I have very little experience with Kinect_co_ I do not know which it is supposed to be.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tA less benign issue is when calling AcquireLatestFrame() for the body reader.  Before it would never return an error code.  Now it returns a 0x8000000A (E_PENDING_co_ _qt_ The data necessary to complete this operation is not yet available. _qt_) when there is no body detected.  I was checking my return code and wrote a problem to console then ignored the frame_co_ so nothing bad happened except a whole bunch of errors I had never seen before.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tI &amp_sm_ other examples I have seen_co_ am checking further down in code to make sure there was at least 1 body.  The net effect is the body-less frame just gets ignored at a different point in the code.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tJust letting you know.  The color reader also has an AcquireLatestFrame().  It could also just be as a result of rebooting.  I rarely re-boot.  I am using sleep as a poor man_t_s SSD drive_co_ even though I have an M.2 socket on my motherboard.  The grief of trying reload on a DDS is not worth it.\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"},{"Owner":"JCPalmer","Date":"2018-02-26T19:12:25Z","Content":"_lt_div class_eq__qt_mages_qt__gt_\n\t\t\t\n_lt_p_gt_\n\tI have not done anything with this in a couple of weeks.  Once the C++ &amp_sm_ corresponding python DLL loading was done_co_ then it fell to actually using the data.  It got ugly fast.\n_lt_/p_gt_\n\n_lt_p_gt_\n\tJust an FYI_co_ I posted a topic to _lt_a href_eq__qt_https_dd_//blender.stackexchange.com/questions/101835/mapping-kinect-data-to-armature_qt_ rel_eq__qt_external nofollow_qt__gt_Blender Stack Exchange_lt_/a_gt_ asking there.  I doubt many here could deal with Blender at the Python level.  I reused the .blend link of the first post to add a script (in a Text editor window) with one frame of data &amp_sm_ one of the failed ways I tried to assign it.\n_lt_/p_gt_\n\n\n\t\t\t\n\t\t_lt_/div_gt_\n\n\t\t_lt_div class_eq__qt_ipsI_qt__gt__lt_/div_gt__lt_/div_gt_"}]